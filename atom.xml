<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zanegjun.github.io</id>
    <title>ZaneGJun Blob</title>
    <updated>2020-02-10T10:56:15.240Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://zanegjun.github.io"/>
    <link rel="self" href="https://zanegjun.github.io/atom.xml"/>
    <subtitle>记录文字</subtitle>
    <logo>https://zanegjun.github.io/images/avatar.png</logo>
    <icon>https://zanegjun.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, ZaneGJun Blob</rights>
    <entry>
        <title type="html"><![CDATA[《全局光照技术》笔记第三章-图形处理器接口]]></title>
        <id>https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-di-san-zhang-bi-ji-tu-xing-chu-li-qi-jie-kou</id>
        <link href="https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-di-san-zhang-bi-ji-tu-xing-chu-li-qi-jie-kou">
        </link>
        <updated>2020-02-09T13:25:03.000Z</updated>
        <content type="html"><![CDATA[<h1 id="31-渲染管线综述">3.1 渲染管线综述</h1>
<p>  从宏观角度，我们可以把OpenGL图形接口相关内容划分为三大块:</p>
<ul>
<li>CPU宿主应用程序与GPU渲染管线的交互</li>
<li>GPU中各种OpenGL对象</li>
<li>几种不同的渲染管线</li>
</ul>
<p>  <mark><strong>理解宿主程序与渲染管线进行交互的关键是状态机的概念。</strong></mark> 宿主程序并不能直接调用GPU执行一个命令，而是通过一个状态机来记录所有宿主程序当前要执行GPU应用程序的各种状态，这些状态的设置占据了大部分图形接口的内容，然后宿主通过Draw等相关的命令将这些状态及后面讲述的各种OpenGL对象提交到GPU中，GPU开始根据各种状态的设置开始执行图形渲染，或者纯粹的计算工作(如计算着色器)，或者其他一些特殊命令(例如将OpenGL缓存中的数据读取回主程序)。<br>
  状态信息很多是用于控制各种OPenGL对象以及这些对象的读写操作。<strong>由于宿主程序不能直接获取GPU内存的指针地址，所欲一个OpenGL对象包含各种状态信息用来指导该对象在OpenGL被怎么使用，例如<mark>大小，数据类型，对象类型</mark> 。</strong> 另一方面，<mark>这些对象大部分不是有着色器分配的，所以我们在编写着色器程序的时候并不能直接取得这些OpenGL对象的引用，那么OpenGL中对于主色去程序访问这些OpenGL对象严重地依赖于一种绑定(Binding)机制。</mark> 着色器程序在被编译和链接的时候会给每个属性分配一个索引地址，宿主程序可以将这些索引地址绑定到某个OpenGL对象上，然后在GPU中执行的时候OpenGL执行环节就可以正确获取到要访问的数据；也有其他OpenGL状态用来控制这种着色器对OpenGL对象的访问，例如是否需要对纹理进行某种方式的过滤操作。<br>
  设置完各种OpenGL对象的状态，以及绑定这些对象到着色器中的属性索引，并将这些对象(包括着色器对象)上传到GPU之后，OpenGL执行环境便开始执行各种管线。除了使用最多的光栅化管线，我们还可以将渲染管线中对顶点的处理结果存储在变换反馈缓存中，并且终止片元着色器的执行，这可以用来使用GPU进行一些变换或者细分操作，并将这些操作结果读回到宿主程序或者供后续的管线作为顶点数据使用。</p>
<h1 id="32-opengl对象">3.2 OpenGL对象</h1>
<p>  <strong>GPU编程模型相较CPU程序最大的区别在于内存对象的使用。</strong> <mark>在GPU并行编程中，内存对象通常并不由这些内核函数或者着色器直接分配(仅供线程内部使用的本地变量除外)，因为并行程序在执行的时候会有多个实例，所以这些实例只能分配本地实例内使用的本地变量，对于全局变量，只有有调度这些实例的“宿主”程序进行分配，这就需要某种机制将外部程序分配的全局变量绑定到内核函数中的变量上。</mark><br>
  因此OpenGL使用一个状态列表来管理OpenGL对象，每个对象都拥有自己的状态列表，不同类型的对象拥有各自不同的状态列表，这些对象状态最终作为整个OpenGL状态的一部分被提交到GPU供着色器或者其他固定管线阶段使用。在OpenGL中为了修改一个对象的状态值，首先需要绑定它到OpenGL上下文中，这通过如下命令：</p>
<pre><code>void glBind*(GLenum target, GLuint object);
</code></pre>
<p>其中target参数指示该对象的用途，OpenGL使用target来区分不同用途的对象。<br>
  当绑定一个OpenGL对象到一个目标后，后续所有对该目标进行修改的命令都会修改该绑定对象的状态。OpenGL使用这种方式修改对象，是因为大部分OpenGL命令的调用都不是立即发送到GPU执行的，他们被保存为一个命令列表，这些前置命令相当于对一个渲染管线的各种设置，包括对固定管线的控制火灾着色器程序会使用的数据(如纹理和顶点数组)，当所有设置完毕后，我们才通过Draw相关的函数通知GPU执行渲染管线，此时才会将所有这些设置发送到GPU开始执行(包括上传所有OpenGL对象的数据到GPU)。<br>
  由于OpenGL通过这种绑定机制来修改OPenGL对象的状态，所以当我们修改完一个对象后，应该立即对该对象进行解绑，以防止后面的命令可能对该对象进行超出预期的修改。可以绑定到每种目标对应的默认对象，即名称为0的对象执行解绑。<br>
  需要注意，每个OpenGL对象都是具有一定类型的，并且每种类型都分别实现OpenGL某些方面的功能，我们必须分配相应类型的对象来实现特定的功能。<br>
  通过以上内容，我们可以看出一个OpenGL对象有 <strong><mark>类型</mark></strong> 和 <strong><mark>用途</mark></strong> 两种属性：</p>
<ul>
<li>类型：基本上定义一个对象在接口层面的用法，比如所有缓存对象的用法都是一致的，下表为所有对象的类型:</li>
</ul>
<table>
<thead>
<tr>
<th>标识符</th>
<th>对象类型</th>
<th>是否容器</th>
</tr>
</thead>
<tbody>
<tr>
<td>GL_BUFFER</td>
<td>缓存对象</td>
<td>否</td>
</tr>
<tr>
<td>GL_SHADER</td>
<td>着色器对象</td>
<td>否</td>
</tr>
<tr>
<td>GL_PROGRAM</td>
<td>着色程序对象</td>
<td>否</td>
</tr>
<tr>
<td>GL_VERTEX_ARRAY</td>
<td>顶点数组对象</td>
<td>是</td>
</tr>
<tr>
<td>GL_QUERY</td>
<td>查询对象</td>
<td>否</td>
</tr>
<tr>
<td>GL_PROGRAM_PIPELINE</td>
<td>程序管线对象</td>
<td>是</td>
</tr>
<tr>
<td>GL_TRANSFORM_FEEDBACK</td>
<td>变换反馈对象</td>
<td>是</td>
</tr>
<tr>
<td>GL_SAMPLER</td>
<td>采样器对象</td>
<td>否</td>
</tr>
<tr>
<td>GL_TEXTURE</td>
<td>纹理对象</td>
<td>否</td>
</tr>
<tr>
<td>GL_RENDERBUFFER</td>
<td>渲染缓存对象</td>
<td>否</td>
</tr>
<tr>
<td>GL_FRAMEBUFFER</td>
<td>帧缓存对象</td>
<td>是</td>
</tr>
</tbody>
</table>
<ul>
<li>用途：一个对象在OpenGL具体被用来做什么，它还需要被绑定到一个用途对象的绑定目标上，下面列出一个缓存类型的对象可以被绑定的绑定目标：</li>
</ul>
<table>
<thead>
<tr>
<th>目标名称</th>
<th>用途</th>
</tr>
</thead>
<tbody>
<tr>
<td>ARRAY_BUFFER</td>
<td>顶点属性</td>
</tr>
<tr>
<td>ATOMIC_COUNTER_BUFFER</td>
<td>高性能原子计数器存储</td>
</tr>
<tr>
<td>COPY_READ_BUFFER</td>
<td>缓存复制源</td>
</tr>
<tr>
<td>COPY_WRITE_BUFFER</td>
<td>缓存复制目标</td>
</tr>
<tr>
<td>DISPATCH_INDIRECT_BUFFER</td>
<td>间接计算着色器分发命令</td>
</tr>
<tr>
<td>DRAW_INDIRECT_BUFFER</td>
<td>间接绘制命令参数</td>
</tr>
<tr>
<td>ELEMENT_ARRAY_BUFFER</td>
<td>顶点数组索引</td>
</tr>
<tr>
<td>PIXEL_PACK_BUFFER</td>
<td>像素读取目标（读回CPU端）</td>
</tr>
<tr>
<td>PIXEL_UNPACK_BUFFER</td>
<td>纹理数据目标</td>
</tr>
<tr>
<td>QUERY_BUFFER</td>
<td>查询结果缓存</td>
</tr>
<tr>
<td>SHADER_STORAGE_BUFFER</td>
<td>着色器的读写存储</td>
</tr>
<tr>
<td>TEXTURE_BUFFER</td>
<td>纹理数据缓存</td>
</tr>
<tr>
<td>TRANSFORM_FEEDBACK_BUFFER</td>
<td>变换反馈缓存</td>
</tr>
<tr>
<td>UNIFORM_BUFFER</td>
<td>着色器的常量块存储</td>
</tr>
</tbody>
</table>
<h1 id="33-缓存对象">3.3 缓存对象</h1>
<p>  <mark>缓存对象是GPU中一块具有任意尺寸，无格式的线性内存区域，它是一个字节数组，可以用来存储顶点数组，从图像或者帧缓存获取的数据，缓存对象在OpenGl中有广泛的用途。</mark></p>
<h2 id="331-缓存对象的存储分配">3.3.1 缓存对象的存储分配</h2>
<p>  在定义一个缓存对象的数据存储之前，必须首先绑定到对应用途的目标，可以用如下命令：</p>
<pre><code>void glBindBuffer(enum target, uint bufferName);
</code></pre>
<p>  缓存对象在上传数据或者被使用之前必须首先为其分配内存，有两种方式：</p>
<ul>
<li>可改变存储</li>
<li>不可变存储</li>
</ul>
<h3 id="3311-不可变存储">3.3.1.1 不可变存储</h3>
<p>  意思是宿主程序声明该对象的这块内存一旦分配之后就是固定不变的(例如不可修改大小)，但是它的部分或者全部内容是可以改变的，类型C++常量指针。要对缓存对象分配不可变缓存，使用以下接口：</p>
<pre><code>void glBufferStorage(GLenum target, GLsizeiptr size, const GLvoid *data, GLbitfield flags);
</code></pre>
<h3 id="3312-可变存储">3.3.1.2 可变存储</h3>
<p>  即是可修改的存储，修改主页包括两方面，一是宿主程序显示的上传二进制数据到GPU（包括相应的GL命令可能修改缓存对象的大小），另一方面是OpenGL渲染管线可能会修改缓存对象的数据。  创建可变的缓存对象数据存储，使用以下接口：</p>
<pre><code>void glBufferData(enum target, sizeiptr size, const void *data, enum usage);
</code></pre>
<h2 id="332-缓存对象数据的修改">3.3.2 缓存对象数据的修改</h2>
<p>  上面所说我们知道可以使用glBufferData修改缓存对象数据，然而其原理是对整个缓存对象的存储进行重新分配，当我们想只修改一部分数据，我们可以有用以下接口：</p>
<pre><code>void glBufferSubData(enum target, intptr offset, sizeiptr size, const void *data);
</code></pre>
<p>  虽然这个接口能用来方便地更新缓存对象部分或者全部内容，但是它会导致OpenGL进行一次数据的拷贝操作，这会带来一定的资源浪费。<br>
  如果能得到一个缓存对象的“指针”，我们就可以直接将算法产生的数据复制给这个指针，而不需要一个专门的临时区域用来存储整个数据对象。我们可以用以下接口实现映射，注意当一个缓存对象被映射后，可以随时接触该缓存对象的绑定，但是除非使用GL_MAP_PERSISTENT_BIT设置创建的可变的缓存对象，否则我们不能调用任何指令导致OpenGL缓存对象进行读写操作。</p>
<pre><code>void *glMapBufferRange(GLenum target, GLintptr offset, GLsizeiptr length, GLbitfield access);
</code></pre>
<p>  使用完映射指针后，必须用以下接口接触映射指针以使缓存对象变得重新可用：</p>
<pre><code>GLboolean glUnmapBuffer(GLenum target);
</code></pre>
<p>  缓存对象的部分或者全部数据清除，通常将其填充为一个特定的值，清除操作使用以下接口,这些接口都不会对缓存对象的存储进行重新分配。</p>
<pre><code>void glClearBufferData(GLenum target, GLenum internalformat, GLenum format, GLenum type, const void *data);
void glClearBUfferSubData(GLenum target, GLenum internalformat, GLintptr offset, GLsizeiptr size, GLenum format, GLenum type, const void *data);
</code></pre>
<p>  缓存对象的数据也可以从另一个缓存对象复制，首先我们需要绑定复制源和复制目的地缓存对象到对应的目标target，然后使用以下接口进行复制：</p>
<pre><code>void glCopyBufferSubData(GLenum readtarget, GLenum writetarget, GLintptr readoffset, GLintptr writeoffset, GLsizeiptr size);
</code></pre>
<p>  OpenGL提供了一种使缓存对象无效的机制，如果一个缓存对象或者它的部分区域无效，意味着它的数据内容是未定义的。</p>
<h2 id="333-缓存对象的流式更新">3.3.3 缓存对象的流式更新</h2>
<p>  <mark>流式更新的基本机制是一个缓存对象在被OpenGL使用的同时，宿主程序可以向其更新数据，这相当于把一整个数据集拆分成多个子集达到类似完全的流式更新的效果，这个拆分粒度不必太小，只需要不带来CPU和GPU的空闲即可。工作流程如下：首先向缓存对象更新一部分数据，然后调用渲染管线开始使用这部分数据进行渲染：在OpenGL开始执行的同时，宿主程序开始更新另一块数据，以此类推。这种流式更新的机制遵循“更新/使用”模型，如果小心处理完全不需要考虑数据和执行同步的问题，并且更新操作发生在同一个缓存对象上，所有几乎不影响整个渲染的执行。</mark><br>
  有以下几种方案：</p>
<ul>
<li>使用多个缓存对象。OpenGL渲染管线在使用其中一个缓存对象时，宿主程序可以开始修改另一个缓存对象。主要问题是需要使用多个缓存对象，以及因此带来的图形接口调用的复杂性。</li>
<li>缓存对象数据重定义。在每次修改缓存对象的数据之前重新分配缓存对象的内存，也称为缓存孤立，在OpenGL上称为对象失效。有两种方法实现，一是glBufferData使用NULL作为data参数，这样OpenGL会为缓存对象重新分配一块一样大小的内存，之前的孽畜变得失效，但是它仍然可以被缓存对象在被修改前的命令调用。由于新数据的分配只是一个未定义的NULL，因此不用担心同步问题。二是glMapBufferRange命令并设置GL_INVALIDATE_BUFFER_BIT位，这些都是在修改数据前使其缓存对象数据无效，后续的数据修改都会被分配到新的存储空间。</li>
<li>缓存更新。调用glMapBufferRange时设置GL_MAP_UNSYNCHRONIZED_BIT，告诉OpenGL完全不需要考虑同步问题，宿主程序会保证不会在任何之前的OpenGL渲染操作还在使用缓存数据之前更新缓存的内容。宿主程序必须保证数据和执行的同步。基本用法是，宿主程序对同一个缓存对象进行渐进式更新，每次更新一小块数据，然后调用OpenGL渲染管线使用这块数据，同时开始更新下移块数据，如此反复，每次更新的数据之间是不重叠的，所以不会有同步问题。</li>
</ul>
<h1 id="34-着色器和着色器程序">3.4 着色器和着色器程序</h1>
<p>  着色器对象和着色器程序对象是一类特殊的OpenGL对象，他们用来封装这些可执行程序(即着色器)，以及执行这些着色器需要的各种状态配置。一个着色器对象(Shader Object)封装一个特定类型的着色器程序，有GLSL编写，这段程序构成一个字符串。<strong><mark>着色器程序需要经过编译以生成其对应语言的程序片段。</mark></strong><br>
  <mark>一个着色器程序就像C++中的各个单独的源文件，要想被OpenGL执行，必须将所有的着色器程序链接起来，形成一个可执行文件。</mark> 在OpenGL中这个可执行文件有着色器程序对象(Shader program object)封装。关于着色器相关OpenGL接口如下:</p>
<pre><code>//着色器对象相关接口
GLunit glCreateShader(CLenum shaderType);
void glShaderSource(GLuint shader, GLsizei count, const GLchar **string, const GLint *length);
void glCompileShader(GLuint shader);

//着色器程序对象相关接口
GLunit glCreateProgram();
void glAttachShader(GLuint program, GLuint shader);

void glUseProgram(GLuint program);
</code></pre>
<h2 id="341-着色器程序的链接">3.4.1 着色器程序的链接</h2>
<p>  可以使用以下接口来链接着色器程序:</p>
<pre><code>void glLinkProgram(uint program);
</code></pre>
<p>  <mark>着色器中使用的变量并不包含在着色器程序对象内部，它们同城被独立地存储在缓存对象或者其他OpenGL对象中，因此着色器程序的链接必须要告诉每个着色器从内存中的那些对象及位置去获取这些数据；另外，不同阶段的着色器之间是可以传递数据的，例如顶点着色器输出的值被插值后作为片元着色器的输入值，这种情况下由于着色器之间并不像C++程序文件那样可以直接饮用(每个着色器是完全独立的)，所以也需要链接阶段来确保这些变量之间的正确传递工作，所有这些配置称为着色器程序对象状态的一部分。</mark><br>
  着色器中的每个变量名称在链接的时候都被分配一个整形文职，根据每种变量类型的不同，OpenGL内部知道怎样读取这些数据值。如下：</p>
<ul>
<li><strong>全局变量</strong> 可以被所有着色器访问的变量</li>
<li><strong>顺序访问</strong> 缓存对象的数据本身是某种固定格式的数据，如顶点缓存对象保存的某个顶点属性的值，以及帧缓存上的颜色缓存保存的一个像素的颜色值，每个着色器实例通常按照某种顺序访问这类数组数据的一个元素。这种情况只需要为每个变量分配一个位置，当这个位置被绑定到一个缓存对象之后OpenGL就可以根据相应的格式为每个着色器是咧获取到相应数据。</li>
<li><strong>乱序访问</strong> 对于纹理对象，着色器必须有随机访问的能力。</li>
</ul>
<p>  上述这些着色器变量的位置在链接之后就会被自动分配，此外我们还可以在执行链接前手动给这些变量设定固定的位置。在着色器程序链接之后我们就可以查询到这些变量被分配的位置，并且这些位置不能再被修改（除非重新链接），然后宿主程序再将这些变量位置绑定到对应的纹理上。</p>
<h2 id="342-接口块">3.4.2 接口块</h2>
<p>  着色器中的变量按照类型分成一些不同的组，每个组是一个接口块，每种类型可以有多个块，包括：着色器输入变量，着色器输出变量，全局变量，以及存储缓存变量。</p>
<h3 id="3421-基于缓存的接口块">3.4.2.1 基于缓存的接口块</h3>
<p>  着色器内部，高度结构化的数据(如顶点数据)被高效地使用如之前讨论的全局内存合并这样的技术进行访问，对于只在着色器内部分配和使用的变量，它们被存储在寄存器或者本地存储中，<mark>而对于非结构化的可被多个着色器实例共享的数据，在OpenGL中则使用uniform或者buffer类型的接口块来存储和使用</mark>，这样的接口块称为介于缓存的接口块，包括 <strong><mark>uniform和buffer</mark></strong> 两种类型。</p>
<h2 id="343-接口匹配">3.4.3 接口匹配</h2>
<p>  <mark><strong>渲染管线中不同阶段着色器都具有一些输入和输出值，大多数时候前有一个管线阶段输出(out块)的值被后一个相邻阶段的着色器消费(in块)，因此在链接着色器程序的时候，OpenGL还必须做接口匹配，不匹配的输入输出接口将导致链接失败。</strong></mark> 主要包含两个方面的匹配：</p>
<ul>
<li>相邻两个阶段的着色器内in/out块之间的匹配</li>
<li>多个着色器内uniform核buffer块的匹配</li>
</ul>
<p>  <mark>首先多个阶段的着色器的链接要求所有前一阶段着色器输出的接口块必须被后以阶段的着色器消费，反之，所有后一阶段着色器中的输入值必须匹配前一阶段着色器的输出值（顶点着色器除外）</mark>。这个匹配工作是必须的，因为存储这些输入输出值的缓存对象是渲染管线的一些中间产物，它并不需要我们手动去维护这些缓存对象(最后阶段输出的颜色缓存除外),这样相邻两个着色器对这些中间缓存对象的使用必须遵循一些规则，才能使OpenGL知道怎样去使用这些缓存对象，例如使用匹配的接口块定义则可以让OpenGL知道每个着色器实例的每个接口块对应于缓存对象的哪一段数据，以及每个接口块内部的每个变量的数据来自缓存对象的哪一段范围。</p>
<h1 id="35-纹理">3.5 纹理</h1>
<p>  纹理对象有别于缓存对象，缓存对象可以用来存储任意格式数据，但是纹理对象是高度格式化的，纹理的格式以颜色为基础，并且具有维度；其次不同于缓存对象存储的是一些离散的精确的值，纹理对象的数据表示的是某个作用域下的某个特征值的分布，如一个2D纹理可以表示一个物体表面颜色的分布，如果我们能够以一个具有少数变量表示的多项式来表征这些同样的分布，那么一个纹理对象完全可以使用这个公式来代替，因此纹理对象的数据存储的是一个函数。<mark>在OpenGL中，纹理是一个包含一个或多个图像的容器对象。</mark> 纹理有三个属性：</p>
<ul>
<li>纹理类型 定义纹理内的图像如何排列</li>
<li>纹理尺寸 定义纹理中每个图像的尺寸</li>
<li>图像格式 定义每个像素的格式刷，纹理中的像素通常称为纹素</li>
</ul>
<p>纹理的类型表:</p>
<table>
<thead>
<tr>
<th>目标 GL_TEXTURE_*</th>
<th>采样器类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1D</td>
<td>sampler1D</td>
<td>所有图像都是1维，具有宽度，没有高度和深度</td>
</tr>
<tr>
<td>2D</td>
<td>sampler2D</td>
<td>所有图像都是2维，具有宽度和高度，没有深度</td>
</tr>
<tr>
<td>3D</td>
<td>sampler3D</td>
<td>所有图像都是3维，具有宽度，高度和深度</td>
</tr>
<tr>
<td>RECTANCLE</td>
<td>samplerRect</td>
<td>只包含一个2维的图像，并且没有mipmap,用于采样的纹理坐标没有被归一化</td>
</tr>
<tr>
<td>BUFFER</td>
<td>samplerBuffer</td>
<td>值包含一个1维的图像，没有mipmap，纹理的数据存储在一个缓存对象中</td>
</tr>
<tr>
<td>CUBE_MAP</td>
<td>samplerCube</td>
<td>包含6个2维的图像集合，每个图像具有相同的尺寸，表示一个立方体的6个面</td>
</tr>
<tr>
<td>1D_ARRAY</td>
<td>sampler1DArray</td>
<td>包含多个1维图像的集合，它的尺寸包括数组的长度</td>
</tr>
<tr>
<td>2D_ARRAY</td>
<td>sampler2DArray</td>
<td>包含多个2维图像的集合，它的尺寸包括数组的长度</td>
</tr>
<tr>
<td>CUBE_MAP_ARRAY</td>
<td>sampler1DCubeArray</td>
<td>包含多个立方体图像的集合，数组的长度*6是纹理尺寸的一部分</td>
</tr>
<tr>
<td>2D_MULTISAMPLE</td>
<td>sampler2DMS</td>
<td>只包含一个2维图像，没有mipmap，但是每个像素包含多个采样点(而不是一个)</td>
</tr>
<tr>
<td>2D_MUTILSAMPLE_ARRAY</td>
<td>sampler2DMSArray</td>
<td>包含多个2维多重采样纹理图像的集合</td>
</tr>
</tbody>
</table>
<h2 id="351-纹理的创建">3.5.1 纹理的创建</h2>
<p>  纹理创建接口：</p>
<pre><code>void glGenTextures(GLsizei n, GLuint *textures);
</code></pre>
<p>  当纹理的名称被创建后，它还没有维数和类型，只有第一次绑定到目标后才能决定其类型，初始绑定的目标决定了创建的纹理类型，从这时起，纹理将只会绑定到这个目标上，直到被销毁为止。<br>
  绑定函数:</p>
<pre><code>void glBindTexture(GLenum target, GLuint texture);
</code></pre>
<p>  在OpenGL着色器中可以使用多个纹理，类似前面讲述的索引目标，OpenGL为每个纹理分配一个整数的索引，称为纹理单元，所以和索引目标一样，每个纹理对象还必须绑定到对应的纹理单元。这必须在glBindTexture之前调用以下命令：</p>
<pre><code>void glActiveTexture(GLenum texture);
</code></pre>
<p>  该命令激活一个纹理单元，然后后续的对纹理的操作都会被关联到这个纹理单元上。在OpenGL着色语言中纹理必须通过一个采样器来对其进行采样，所以着色器使用的纹理单元数量通过采样器变量的数量来决定。<br>
  一个纹理创建使用过程:</p>
<pre><code>//着色器中定义有一个采样器
uniform sampler2D tex1;

//则宿主程序使用方式:
glUseProgram(prog);

GLint tex1_uniform_loc = glGetUniformLocation(prog, &quot;tex1&quot;);
glUniform1i(tex1_uniform_loc, 0);
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_2D, tex1);
</code></pre>
<p>  不同于索引目标被OpenGL自动分配，纹理单元需要手动分配，纹理单元的值是OpenGL定义的一系列枚举值，分别命名为GL_TEXTUREi, 其中i在0到k-1范围，k表示纹理单元的最大数目，所以GL_TEXTUREi的值等于GL_TEXTURE0+i。<br>
  创建一个纹理对象后，必须设置存储和数据。存储和缓存对象一样有可变和不可变之分。不可变还包括纹理的格式和尺寸，可以用以下命令：</p>
<pre><code>void glTexStorage1D(GLenum target, GLsizei levels, GLenum internalFormat, GLsizei width);
void glTexStorage2D(GLenum target, GLsizei levels, GLenum internalFormat, GLsizei width, GLsizei height);
void glTexStorage3D(GLenum target, GLsizei levels, GLenum internalFormat, GLsizei width, GLsizei height, GLsizei depth);
</code></pre>
<p>  可变存储用以下接口，<mark>这里列出的纹理内部格式，大小，mipmap级数以及纹理数据都可以被每次调用这些命令的时候改变。</mark></p>
<pre><code>void glTexImage1D(GLenum target, GLsizei levels, GLenum internalFormat, GLsizei width, GLint border, GLenum format, GLenum type, const void *data);
void glTexImage2D(GLenum target, GLsizei levels, GLenum internalFormat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, const void *data);
void glTexImage3D(GLenum target, GLsizei levels, GLenum internalFormat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, const void *data);
</code></pre>
<h2 id="352-像素传输">3.5.2 像素传输</h2>
<p>  <mark>客户内存的数据通常是未格式化的，称为编码的，所以像素传输由客户内存向设备内存的过程称为像素解码操作，而由设备内存向客户内存传输的过程称为像素编码操作。</mark><br>
  在OpenGL中，像素数据 有设备内存传输到客户内存（编码）的相关命令：</p>
<pre><code>//从当前绑定的帧缓存中读取像素数据道客户端内存
glReadPixels(); 
//读取当前绑定的某个纹理对象中某个mipmap级别的所有数据道客户端内存
glGetTexImage();
</code></pre>
<p>  像素数据有客户内存传输到设备内存(解码)的命令：</p>
<pre><code>//为一个额纹理对象的某个mipmap级别分配可改变的存储空间，该命令也可用直接传输输出
glTexImage*();
//将客户内存中的纹理数据写入到一个当前绑定的纹理对象的某个mipmap级别
glTexSubImage*();
</code></pre>
<h2 id="353-压缩纹理">3.5.3 压缩纹理</h2>
<p>  压缩纹理是指一种基于GPU的纹理压缩方法，有别于传统压缩方案如JPG，该方法GPU可以直接从压缩纹理中采样进行渲染。因此由于纹理在设备内存中以压缩格式存在，所以此方法不仅能减少资源大小，同时能减少内存占用。</p>
<h3 id="3531-压缩纹理的特点">3.5.3.1 压缩纹理的特点:</h3>
<ul>
<li>解压速度快：为了不影响渲染系统的性能，因此压缩纹理具有快速的解压速度。</li>
<li>随机读取：传统的 压缩技术如JPEG使用可变的压缩比率，读取某个像素的信息可能要解压很大一部分相关的像素信息。压缩纹理技术则使用固定的压缩比率，访问纹素时可以根据索引快速读取某一小块的内容，从而可以高效地实现随机读取。</li>
<li>压缩率和图像质量：通常使用有损压缩</li>
<li>编码速度：一般离线生成，不需关注</li>
</ul>
<p>  压缩纹理同时减少了应用程序客户端向GL服务端传输纹理数据的带宽，由于减少内存以及其直接存储在GPU中，因此芯片可以对其进行更高效的使用，<mark>从而可以减少移动设备电量的消耗。</mark></p>
<h3 id="3532-压缩纹理的实现">3.5.3.2 压缩纹理的实现</h3>
<p>  传统的图像压缩算法为了保证最大的压缩比，使用一个可变的压缩比率，这就要求在解压的时候要解压更多的像素位才能读取某个像素的位置，这对于随机和快速读取是做不到的，实际上传统压缩算法为了存储，传输等目的设计，而不是为了实时渲染。<br>
  <mark>所以压缩纹理使用一个固定的比率，它首先按照这个比率将纹理分成很多的像素块(block)，每个像素块包含如2x2或者4x4个像素，然后对每个像素块进行压缩。每个被压缩后的像素信息存储在一个像素块集合中，而一个块索引图存储了每个 x=像素块 的索引位置，在读取的时候首先根据块索引找到像素块，然后解压该像素块读取偏移值的信息。</mark><br>
  这种快速解压的速度使得图形渲染管线可以不依赖CPU的解压就可以实现实时渲染，将压缩纹理直接保存在GPU内存中，既减少了资源在磁盘的存储大小，也大大节省了内存，还减少了纹理在传输过程中所占用的带宽。</p>
<h2 id="354-采样器对象">3.5.4 采样器对象</h2>
<p>  在OpenGL中，一个纹理对象实际上包含两个类别的参数(或者状态)：</p>
<ul>
<li>表示纹理的尺寸，维度以及其他图像相关的参数</li>
<li>采样相关参数</li>
</ul>
<p>  一个采样器对象是一个标准的OpenGL对象，它使用glGenSamplers,glDeleteSamplers命令来创建和删除，并使用glBindSampler命令来绑定采样器对象到某个纹理单元，不同的是它可以同时被绑定到多个纹理单元上。<br>
  <mark>采样器最重要的参数是用来对离散函数进行重采样的滤波器的设置，包括信号的放大和缩小。</mark></p>
<ul>
<li><strong>放大过滤器</strong> 对应参数为GL_TEXTURE_MAG_FILTER，可选为GL_LINEAR和GL_NEAREST，分别表示使用线性插值和最近点作为采样值。</li>
<li><strong>缩小过滤器</strong> 采样参数的设置还涉及mipmap的选择，我们可以选择不使用更小的mipmap级别，或者我们也可以选择对mipmap进行采样。</li>
</ul>
<p>  纹理的重采样是硬件支持的功能，它们能够高效地满足着色器的随机存储，这也是纹理对象和一般缓存对象不同的地方。<br>
  采样器的另一些参数用来控制存储深度值的纹理的比较模式。</p>
<h2 id="355-特殊纹理">3.5.5 特殊纹理</h2>
<h3 id="3551-立方体纹理cubemap">3.5.5.1 立方体纹理CubeMap</h3>
<p>  立方体纹理是一种特殊的3D分布函数。<br>
  使用立方体可以很方便地构造环境分布函数，对于环境光来说，只需要将摄像机放置于环境中央，然后正对立方体的6个面分别执行一次普通的渲染工作，这6个面分别用一个等大小的2D纹理来存储颜色数据。这6个2D的面都有自己的mipmap，这跟一般2D纹理一样可以通过glTexImage2D来设置。<br>
  使用立方体纹理对环境进行映射的一个缺点是，6个面之间的连接处会存储不连续的缺陷。传统的纹理滤波器技术只在每个2D纹理内部工作，而不能对这种情况进行处理。但是现代的硬件能够直接在相邻的纹理间进行插值，可以通过以下接口使用这种特性：</p>
<pre><code>glEnable(GL_TEXTURE_CUBE_MAP_SEAMLESS);
</code></pre>
<h3 id="3552-数组纹理">3.5.5.2 数组纹理</h3>
<p>  数组纹理是指在纹理的每个mipmap层级内包含的是一个图像或者图像集的数组，而不是单个图像或者图像集。</p>
<h1 id="36-帧缓存">3.6 帧缓存</h1>
<p>  帧缓存是OpenGL渲染管线的最终目标，由于我们使用图形渲染管线的目的是得到一张2D图像，因此不难想象帧缓存是由一个2维的矩形像素数组构成的图像，它的分辨率和当前设备的显示分辨率一致。因此我们想要得到任何渲染结果，都必须通过帧缓存对象，这包括提交图像给输出设备显示，或者读取渲染结果会宿主程序供其他使用目的如视频流。<br>
  在OpenGL中，帧缓存对象分为两种类别，虽然它们内部结构相似，但是他们的使用差别很大。</p>
<ul>
<li>
<p><strong>默认帧缓存</strong> <mark>有宿主程序在创建OpenGL上下文的时候形成，默认帧缓存仅供显示使用，应用程序不能做太多控制。</mark></p>
</li>
<li>
<p><strong>应用程序创建的帧缓存</strong> <mark>完全受应用程序控制，即我们常说的FBO(FrameBuffer Object),但是他的渲染结果不能直接被显示，它可以用于将渲染结果保存到纹理对象，甚至用于离线渲染将渲染结果保存会宿主供其他使用。</mark> 随着延迟渲染等渲染方法的想兴起，一次完整的渲染往往需要使用多次渲染管线的计算结果，应用程序创建的帧缓存被大量使用以用来将一些中间结果保存到纹理，最终才将最后的计算结果显示出来。</p>
</li>
</ul>
<p>  帧缓存对象是一个普通的OpenGL对象，因此我们仍然使用一般的glCenFramebuffers和glDeleteFramebuffers来创建和删除帧缓存对象，并使用glBindFramebuffer来绑定要使用的帧缓存对象到当前上下文。<br>
  上述我们假想地认为“一个帧缓存包含一个2D图像”是错误的，<mark>帧缓存实际上是一个容器。</mark> 它包含多个具有相同尺寸的2D图像。帧缓存以附加点的方式让应用程序可以管理这些2D图像，应用程序可以把一个对应的可附件的对象附加到这些附加点，这些附加点的名称可以分为4类，分别用来存储颜色、深度、模板值，其中具有多个用来存储颜色的附加点。</p>
<table>
<thead>
<tr>
<th>帧缓存附加点</th>
<th>缓存名称</th>
</tr>
</thead>
<tbody>
<tr>
<td>GL_COLOR_ATTACHMENTi</td>
<td>颜色缓存,可以有多个，i表示，最小值为8</td>
</tr>
<tr>
<td>GL_DEPTH_ATTACHMENT</td>
<td>深度缓存</td>
</tr>
<tr>
<td>GL_STENCIL_ATTACHMENT</td>
<td>模板缓存</td>
</tr>
<tr>
<td>GL_DEPTH_STENCIL_ATTACHMENT</td>
<td>深度模板缓存</td>
</tr>
</tbody>
</table>
<p>  在OpenGL中，可被附加到帧缓存的每个附加点的对象类型有两种：</p>
<ul>
<li>渲染缓存</li>
<li>纹理</li>
</ul>
<p>  <mark>它们都可以用来实现离线渲染，即将渲染结果都回到客户端内存中，在这方面，渲染缓存是一个更好的被优化的渲染目标；然而当渲染结果需要被着色器重采样(被着色器读取)时，则只能选择渲染到纹理中。</mark><br>
  渲染缓存对象是一个OpenGL对象，渲染缓存不需要分配初始数据，渲染缓存的数据只能被渲染管线写入。在OpenGL中，渲染缓存唯一被使用的方式就是被附加到一个帧缓存对象上。<br>
  默认情况下，片元着色器中的片元颜色计算结果被写入到gl_FragColor输出变量中，这个颜色被写入到帧缓存的默认颜色缓存对象中，然而OpenGL同样提供一种称为 <strong><mark>多重渲染目标(Multiple-render targets)</mark></strong> 技术，可以在一个片元着色器中将多个颜色值同时写入到多个缓存对象，这种机制在后面讲述的延迟渲染等技术中非常关键。多种渲染目标是一种性能的优化方案，它可以避免多次处理同一组顶点列表而浪费时间，并且不需要多次对图元进行光栅化。<br>
  要使用多重渲染目标，首先使用前面讲述的方法将多个图像附加到帧缓存的各个附加点，然后建立片元着色器中一些输出变量和这些附加点之间的关系。片元着色器是通过out变量来输出数据的，如果要设置out变量与帧缓存附加点之间的对应关系，我们只需要使用layout限定符来设置每个变量的位置即可，如:</p>
<pre><code>layout (location=0) out vec4 color;
layout (location=1) out vec4 normal;
</code></pre>
<p>要使用多重渲染目标，在绘制之前还必须告知哪些附加点可以被写入(否则只有默认颜色缓存可以被写入)，可用如下接口:</p>
<pre><code>glDrawBuffer(GLsizei n, const GLenum* buffers);
</code></pre>
<p>  <mark><strong>渲染到纹理的机制使得渲染管线不再是一个单一的渲染通道，我们可以对整个渲染工作的流程进行逻辑划分，在前面和中间的流程中可以将一些中间结果渲染到纹理，然后这些纹理可以被后面的流程灵活使用，这种思路是现代实时渲染技术的重要基础。</strong></mark></p>
<h1 id="37-顶点处理">3.7 顶点处理</h1>
<p>  OpenGL渲染管线主要包括两个阶段：</p>
<ul>
<li><strong>顶点处理阶段</strong> 重新计算运动部分物体的坐标，主要用来处理“应用程序”方面的需求，包括对移动物体重新计算坐标，对可是区域之外的几何体执行裁剪，几何体级别的戏份，这些操作可以认为它们不是真正着色的一部分，它们“本应该”在CPU端执行，只不过由于这些操作具有高度的并行性而被放入到GPU执行。</li>
<li>光栅化， 连接上下两个阶段</li>
<li><strong>片元处理阶段</strong> 对每个物体的每个像素点进行着色</li>
</ul>
<h2 id="371-顶点数据定义">3.7.1 顶点数据定义</h2>
<p>  顶点数组是一个数组数据，其数组的长度对应物体顶点的数量，每个数组元素表示的是一个或者多个顶点属性，顶点数组中的数据使用一个缓存对象来存储，称为 <strong><mark>顶点缓存对象(Vertex buffer object, VBO)</mark></strong>。<br>
  OpenGL使用一个顶点数组对象来存储所有顶点数据相关的状态，例如每个顶点属性的格式，分量大小等状态信息，这和纹理，全局变量等其他数据的分散的状态管理是不一致，这是因为顶点数组相关的状态比较复杂，封装在一个容器对象中可以快速地在GPU内部进行状态切换，而不需要每次从客户内存重新上传众多的顶点状态数据。</p>
<h3 id="3711-顶点属性">3.7.1.1 顶点属性</h3>
<p>  每个顶点可以具有多个顶点属性变量，同纹理单元一样，OpenGL也使用一个整数索引来表示每个顶点属性，这个顶点属性索引值在着色器链接后就可以通过以下命令直接获取：</p>
<pre><code>GLint glGetAttribLocation(GLuint program, const char *name);
</code></pre>
<h3 id="3712-顶点缓存对象">3.7.1.2 顶点缓存对象</h3>
<p>  如果顶点属性数据使用数组的形式来存储，它的数据被存储于一个缓存对象中，称为顶点缓存对象(VBO),顶点缓存对象的绑定目标为GL_ARRAT_BUFFER。<br>
  顶点着色器中的顶点属性变量的类型只能是浮点型、整形、双精度浮点型，GPU中通常只包含32位的寄存器，而不像CPU一样具有多种多样数据类型和大小的寄存器，所以GPU中更常用的是32位的整数和32位浮点数，其中对于有符号整数，它的其中一位用来存储符合，所以只有31位用来存储数据，对于双精度浮点数，它使用32位的寄存器来存储。<mark>由此可知，32位的浮点数只有很少的位数用来存储整数部分，如果整数部分取值范围比较大，最好直接用整数存储或者使用双精度的浮点数。</mark></p>
<h3 id="3713-绘制">3.7.1.3 绘制</h3>
<p>  OpenGL使用单独的一个整形数组来表示顶点的顺序，这称为索引数组。索引数组中的元素可以是重复的，这就是上述描述的顶点重复部分，通过重复一个整形的索引值而不是重复多个顶点属性变量可以有效地减少存储空间浪费。<br>
  使用索引数组有两种绘制方式：</p>
<pre><code>void glDrawElements(GLenum mode, GLsizei count, GLenum type, void *indices);

void glDrawArray(GLenum mode, GLint first, GLsizei count);
</code></pre>
<p>   <strong><mark>这也是OpenGL的两个基本绘制命令</mark></strong>,glDrawElements直接使用客户端内存的顶点索引数据，并将其上传至设备内存，其type定义索引数组元素的类型，count定义顶点的数量；glDrawArrays使用顶点索引缓存对象中的索引数据，参数first表示缓存对象中顶点索引开始的偏移位置。</p>
<h5 id="多次合并绘制">多次合并绘制</h5>
<p>  有多个物体使用完全一样的着色器及图元类型，但是他们分别属于不同的物体，这却不得不分别调用多次绘制命令，因为共享顶点的图元类型没法将它们从几何空间上分开，而一次新的绘制导致的VAO的绑定和修改的成本都是极高的。为了优化这种多次相似的绘制，例如场景中存在大量相同类型的物体分布在空间中不同地方，这些物体可以使用以下命令一次性绘制：</p>
<pre><code>void glMultiDrawArrays(GLenum mode, GLint *first, GLsizei *count, GLsizei primcount);
</code></pre>
<p>  内部实现是对每个物体分布调用一次绘制以使每个物体的图元在空间上的位置分开，但是在内部OpenGL会使用一次绘制命令。</p>
<h5 id="多实例绘制instance">多实例绘制(Instance)</h5>
<p>  多实例绘制对 <mark>完全相同</mark> 的顶点数据绘制多次，但是它在着色器内提供一个几何体实例变量gl_InstanceID来使着色器可以决定对不同的实例进行适当的修改(如读取uniform/buffer块数据中的某个表数据)，多实例绘制使用以下接口绘制：</p>
<pre><code>void glDrawArraysInstanced(GLenum mode, GLint first, GLsizei count, GLsizei instancecount);
void glDrawElementsInstanced(GLenum mode, GLsizei count, GLenum type, const void *indices, GLsizei instancecount);
</code></pre>
<p>  对于每个实例，内置变量gl_InstanceID都会一次递增，新的值会被传递到着色器，以区分不同实例的顶点属性，其他参数则和基本的绘制类型一样。</p>
<h5 id="间接绘制">间接绘制</h5>
<p>  间接绘制IDE目的是避免不必要的GPU-&gt;CPU-&gt;GPU的数据复制操作，在OpenGL中，有时候顶点数据来自于渲染管线的中间产物，甚至直接由计算着色器或者其他GPU计算产生的计算结果，这时候这些缓存对象中的顶点的顺序，以及绘制相关的一些参数也是有GPU直接设置的，如果使用传统的绘制命令，则需要将这些参数都读回CPU，然后以参数的方式复制到GPU，造成一些不必要的开支。因此间接绘制命令直接可以从一个缓存对象中读取绘制命令需要的参数。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《全局光照技术》笔记第二章-并行处理器架构]]></title>
        <id>https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-er-zhang-bing-xing-chu-li-qi-jia-gou</id>
        <link href="https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-er-zhang-bing-xing-chu-li-qi-jia-gou">
        </link>
        <updated>2020-02-04T12:14:30.000Z</updated>
        <content type="html"><![CDATA[<h1 id="cpu">CPU</h1>
<h2 id="21cpu应用程序执行模型">2.1CPU应用程序执行模型</h2>
<p>  现代CPU遵循冯·诺依曼提出的处理器架构。在该结构中，一个具有处理单元的点子数字计算机由以下部分组成：</p>
<ul>
<li>一个用于进行二进制运算的算术逻辑单元(ALU)</li>
<li>一个用来告诉存储指令和数据的寄存器组</li>
<li>一个用来控制指令读取的控制单元</li>
<li>一个用于存储所有指令和数据的内存</li>
<li>外加一些大容量存储设备及输入输出设备</li>
</ul>
<p>  通常执行过程为 <mark><strong>处理器从内存中将指令和数据(包括地址)读取到寄存器并解码，然后执行该指令。</strong></mark> 因为程序和数据存储在内存中，和处理器分开，因此数据需要在内存和处理器之间进行传输。随着现代处理器运行速度提高，更多时间用于等待从内存获取数据。主要有以下几个方法用于克服这个瓶颈:</p>
<ul>
<li><strong>缓存</strong> 设计一些容量小，速度快的缓存来减少从主存取数据的时间</li>
<li><strong>预取</strong> 通过在处理器读取数据之前预测可能会读取的数据，从而提前读取到缓存中</li>
<li><strong>多线程</strong> 并发处理，主要有指令级并行、线程级并行、处理器级并行</li>
</ul>
<h3 id="211缓存">2.1.1缓存</h3>
<p>  缓存是一种容量更小，更快的内存，缓存里的数据来自于内存。处理器需要向主存或者指令或者数据是，先查询缓存，如果数据不在L1缓存中，则向L2/L3发出读取请求，如果还是没有则从主存读取。<strong>L1缓存的速度通常能达到或者接近处理器的时钟速度，因此假设写入和读取都是在L1中完成，则指令的执行很有可能接近处理器全速。</strong> L1通常只有16KB或者32KB，L2速度慢些，但是容量更大，通常256KB，L3通常几兆，但是速度最慢。<br>
  在缓存设计中，L1和L2都是每个核独享，而L3则是所有核共享。缓存的设计利用局部性原理，包括时间局部性和空间局部性。时间局部性指之前访问的数据很可能还要被再次访问；空间局部性指刚刚被访问的数据附近的数据，可能马上要被访问。注意缓存命中率与缓存失效，失效可能是第一次访问新的数据，又或者因为缓存的尺寸限制，旧的缓存被LRU给清理了。<br>
  缓存的设计是有代价的，增大缓存会增加芯片面积。</p>
<h3 id="212预取">2.1.2预取</h3>
<p>  预取是指通过在处理器读取数据之前预测可能会被读取的数据，提前读取到缓冲中。一般集成在处理器内部，各级缓存都有自己的预取器。一些编译器如GCC还通过在编译阶段修改源码，在其中插入预期指令实现软件预取。<br>
  最常用的数据预取是 <strong><mark>常数步幅模式</mark></strong>,即根据之前数据访问的模式(在一个常数范围内的步幅)预先载入当前数据邻近对应长度范围的数据。<strong>但是数据预取器不擅长对随机数据的预测</strong>。程序指令在空间上的分布更加线性，其相对数据预取更加简单。然而有以下几种情况使得程序指令出现非线性化：</p>
<ul>
<li>函数指针的应用，由于处理器只有在执行指令的时候才会知道其指令是追踪一个指针，所以指令预取器对函数指针没有办法进行预处理。</li>
<li>分支预测，分支决定只有在条件被计算出来才能发生。所以分支预测必须记录过去的历史数据，以此计算出一定的模式并度后续的分支使用该模式来预测分支走向，这就是各种不同分支预测算法的基础。</li>
</ul>
<h3 id="22并行计算架构">2.2并行计算架构</h3>
<h4 id="221指令级并行">2.2.1指令级并行</h4>
<p>  指令级并行计算称为ILP(instruction-level parallelism),指一个单处理器同时执行多条指令的能力。IPL计数允许编译器和硬件重叠地执行多个指令，或者甚至按不同的顺序执行指令。IPL对程序员是透明的。下面介绍一些比较流行的ILP技术。</p>
<h5 id="2211指令管线化">2.2.1.1指令管线化</h5>
<p>  意思是将一条指令完整的执行流程分成多个阶段，每个阶段允许一条单独的指令执行。<mark>这样的划分有一些重要的原因，处理器内部正度这些特定的阶段都有专门的计算功能，如果一次只处理一条指令，当其中任何一个阶段发生延迟或者缓存失效，都会导致其他功能除以等待空闲状态，不能充分利用处理器的资源。</mark> 一般可以分为经典的5个阶段:</p>
<ol>
<li>IF:获取指令阶段，处理器从L1获取一个32位(64位机则64位)的指令，该操作通常具有1个时钟周期的延迟。</li>
<li>ID/RF：解码指令以及从寄存器获取操作数</li>
<li>EX：执行</li>
<li>MEM：读取内存</li>
<li>WB：写回寄存器</li>
</ol>
<p>  指令管线化通过充分利用各个生产流水线，提高了整个关系的吞吐能力。然后并不能减少延迟，当指令对应阶段出现延迟，该指令将处于停止等待状态。指令管线化假设多哟指令是可以并行执行的，当程序中的指令出现依赖，我们称为一个障碍。一般有下面的方法来处理串行指令的并行障碍</p>
<ul>
<li>
<p><strong>管线气泡</strong><br>
  最简单的一种处理方式，当指令包含障碍是，其将在解码阶段被识别，同时处理器会创建一个气泡占据该指令的解码阶段，使当前管线的解码阶段处于空闲等待状态，管线气泡将导致后续一个或多个指令被延迟。</p>
</li>
<li>
<p><strong>操作数前移</strong><br>
  操作数前移中，处理器需要对指令探测这种依赖性的存在，然后根据探测结果判断是需要从寄存器获取操作数，还是直接通过相关的电路直接获取前一指令的值。</p>
</li>
<li>
<p><strong>乱序执行</strong><br>
  乱序执行基于这个的事实，即如果后面的指令不依赖前面的指令，或者说它此时具备执行指令需要的操作数据，则它可以闲鱼前面的指令被执行。然后乱序执行必须保证指令执行结果输出的顺序与程序顺序保持一致，以保证最终程序运行的正确性。</p>
</li>
<li>
<p><strong>分支预测对指令管线的影响</strong><br>
  分支预测失败会导致处理器放弃并销毁之前所有未执行完且判断错误的分支指令。因为分支的真实走向必须等到if比较指令执行完毕，并且将结果写入到寄存器之后，处理器才会知道真正的分支走向。例如有A是比较执行，BCD是错误的分支走向，只有等到A指令执行完毕才能知道分支走向的正确性，这时候BCD因为流水线的原因，会依次被执行，当A执行完毕处理器知道BCD是错误的走向，需要销毁所有关于BCD在寄存器的数据及其他状态，然后将正确的EFG指令载入执行单元执行指令计算。<br>
  如果if比较函数是对两个浮点数进行比较，代价更高，浮点数比证书的比较要花费更多的时钟周期。<br>
  现代处理大都会采用一种方法避免比较和跳转操作。这种方法基于一个第三个参数，来在两个操作数之间进行选择，而不需要执行比较和跳转指令，这称为条件转移或无分支选择。</p>
</li>
</ul>
<h4 id="222线程级并行">2.2.2线程级并行</h4>
<p>  多线程处理器内部可以支持多个线程并行执行，但是这些线程不是真正地同时执行，而是通过处理器的控制交叉地执行。当当前正在执行的线程遇到缓存失效或者其他事件，处理器即自动切换到其他处于等待执行状态的线程执行指令。<br>
  硬件对多线程支持目标是，允许在等待延迟的线程和已经准备好的被执行线程之间保持快速切换。为了这个目的，每个线程都需要拥有自己的指令和数据寄存器集合，包括用于存储指令管线调度相关的一些处理单元和跳读信息，当发现线程切换，直接在高速的寄存器之间执行赋值和读取，不需要重新从缓存读取数据。现代处理器一般在一个时钟周期内可以完成线程切换。</p>
<h5 id="2221同时多线程技术">2.2.2.1同时多线程技术</h5>
<p>  多线程有多种实现方案:</p>
<ul>
<li>最简单是块多线程(block multithreading)，这种方案会一直执行一个线程，直至线程遇到很大的延迟(如缓存失效,可能需要上百个时钟周期)时才切换到另一个处于&quot;可执行状态&quot;的线程。</li>
<li>较为聪明的方案称为交叉多线程，在每个时钟周期都使用一个不同于上一个时钟周期的线程。因为线程间是相对独立的，每次从不同的线程取出一条指令加入到指令管线，这样理想的情况下指令管线中每个阶段执行的是不同线程中的指令，从而几乎不会有数据依赖关系。但是缺点是每个指令阶段都需要额外的计算和存储成本用来追踪这些线程ID。</li>
</ul>
<p>  上面两种都可以称为时分多线程技术(TMT),对于给定的任何时间，指令管线的每个阶段只有一个线程的指令在执行。而现代处理器比较高级的多线程技术方案是同时多线程技术(SMT)，在一个给定的时间内及指令阶段，SMT处理器可以同时又来自多个线程的指令在执行。</p>
<h4 id="223处理器级并行">2.2.3处理器级并行</h4>
<p>  多处理器架构是指一个计算机系统拥有多个物理额处理器或者拥有多个核，区别为多喝处理器每个核仅拥有L1缓存及寄存器，统一芯片内的核共享L2及主存，而多个单独的物理处理器仅共享主存并拥有自己的缓存系统。</p>
<h5 id="2231多核处理器架构的对等性">2.2.3.1多核处理器架构的对等性</h5>
<p>  对称性指所有处理器的地位和功能是否对等，非对等处理器机构比较典型是Cell处理器架构，思想是用一个常规处理器作为监管处理器，该处理器与大量的告诉协作处理器相连。它跟GPU很像，它独特之处在于摒弃了传统的内存缓存结构，直接将数据和指令直接发送到每个协作处理器的私有内存，让它一次性尽可能做更多计算。协作处理器主要聚焦于数据密集型计算。处理器中，缓存系统占据了很多芯片面积，并且导致能耗增加。这种设计结构能大大减少芯片面积及能耗。</p>
<h5 id="2232多处理器架构的通信方式">2.2.3.2多处理器架构的通信方式</h5>
<p>  多处理器架构可以分为共享内存以及基于网络的消息传递方式。<br>
  共享内存中，每个处理器有自己的缓存系统，但是他们共享整个计算机系统的主内存。需要注意的是缓存一致性问题，这是限制一个处理器中核数不能太多的一个重要因素。<br>
  另一种多处理器架构称为集群，通过将一些独立的通常是廉价的计算机系统，通过网络等方式联通起来，组成一个多处理器系统。适合于线程之间的耦合相对比较弱的计算。</p>
<h1 id="gpu">GPU</h1>
<h2 id="231为什么需要一个并行计算架构">2.3.1为什么需要一个并行计算架构</h2>
<p>  一般的多处理器机构执行大规模并行计算的限制来源于针对串行计算优化的缓存系统。高速缓存系统的成本非常高，并且占用芯片很大面积，操作数从主内存到ALU之间的传输需要耗费大量的电能。这些因素使得基于缓存的处理器系统很难扩张以应付大规模的并行计算。</p>
<h2 id="232内存结构">2.3.2内存结构</h2>
<p>  GPU使用一种称为程序托管的内存模型，即数据额存放地点由程序员决定，因此它要求程序员需要对GPU内存结构有一定了解。而CPU使用一种称为硬件托管的内存模型，缓存会自动根据局部性特征获取当前正在执行指令附近的指令以及当前正在处理数据附近的数据，并在指令将计算结果写入到寄存器之后自动将其写入到缓存系统，以及更新多处理器架构中其他处理器的缓存，一切都是硬件自动完成。<br>
  <img src="https://raw.githubusercontent.com/ZaneGJun/PictureWarehouse/master/2.12_min.JPG" alt="image" loading="lazy"><br>
  上图所示是NIVIDIA的一个GPU内存结构，其中流处理器族(Stream multiprocessor,SM)相当于一个CPU核，每个SM内部有多个流处理器(Stream processor,SP)，每个SP用于执行并行计算 中的一个独立的线程。<br>
  GPU中的内存分为4种:</p>
<ol>
<li>寄存器</li>
<li>共享内存</li>
<li>常量/纹理内存</li>
<li>全局内存</li>
</ol>
<table>
<thead>
<tr>
<th>存储类型</th>
<th>带宽</th>
<th>延迟</th>
</tr>
</thead>
<tbody>
<tr>
<td>寄存器</td>
<td>约8TB/s</td>
<td>1个周期</td>
</tr>
<tr>
<td>共享内存</td>
<td>约1.5TB/s</td>
<td>1-32个周期</td>
</tr>
<tr>
<td>纹理/常量内存</td>
<td>约200MB/s</td>
<td>400-600个周期</td>
</tr>
<tr>
<td>全局内存</td>
<td>约200MB/s</td>
<td>400-600个周期</td>
</tr>
</tbody>
</table>
<h3 id="2321全局内存">2.3.2.1全局内存</h3>
<p>  GPU拥有自己独立的内存，所以宿主程序需要将数据从CPU传输到GPU以计算。通常GPU设备都是通过PCI-E总线与处理器相连，目前PCI-E 3.0 的传输率为8G/s。<br>
  <mark>GPU中的主内存称为全局内存，这是因为GPU和CPU都能对其进行写操作。宿主程序要想在GPU上执行计算，首先将CPU中的数据和指令通过PCI-E总线传输至GPU的全局内存中，接着GPU中的各个内核线程从全局内存中读取数据并执行计算，然后将计算结果写回到全局内存，最后宿主程序再从GPU全局内存中读取数据回CPU。</mark><br>
  数据从CPU传到GPU全局内存以及全局内存到CPU内核函数的寄存器之间的传输都会产生大量的延迟。<strong>全局内存是GPU中内核函数访问最慢的内存</strong>，由于GPU使用程序托管的内存模型，所以内核函数可以选择不需要将每个变量的中间结果都写回到全局内存，这些中间数据可以保存在内核函数所在的执行单元本地，而等到内核函数执行完毕才将本地的数据写回到全局内存。这大大节省了数据在全局内存和内核函数之间的不必要的传输时间。</p>
<h3 id="2322常量纹理内存">2.3.2.2常量/纹理内存</h3>
<p>  常量/纹理内存其实只是全局内存的一种虚拟地址形式，GPU并没有特殊保留的常量/纹理内存，但是常量/纹理内存能够提供高速缓存，此外它们都是只读内存。常量内存合一被缓存到常量内存缓存存储器，纹理内存可以被缓存到纹理内存缓存存储器，这些存储器通常都是L1级缓存，可以提供较全局内存更快的访问速度。<br>
  对于纹理内存，它提供基于硬件的线性插值功能。</p>
<h3 id="2323共享缓存">2.3.2.3共享缓存</h3>
<p>  由前面可知，内核函数的多个线程会被分配到多个SM上执行，据此我们可以对并行计算处理的数据进行一定的划分成多个处理子块，在每个子块内部的多个线程可以共享一些局部数据。这些单个SM内部的局部数据不需要通过缓慢的全局内存进行存储和读取，它们可以被存储在一个SM内部的共享内存中。<br>
  为了提供更高的带宽，共享内存使用的是基于存储器切换的架构，它将共享内存平均分成多个尺寸相同的内存模块，称为存储体，这些存储体内部的孽畜可以被同时使用。任何对共享内存度或者写的操作可以均分到n个不同的存储体地址，每个存储体地址都可以被同时访问，使其可以提供相对于单个内存模块n被带宽。<br>
  但是需要注意的是可能会有存储体冲突。</p>
<h3 id="2324寄存器">2.3.2.4寄存器</h3>
<p>  GPU的每个SM拥有一个巨大的寄存器文件，它通常包含上千个寄存器，这些寄存器平均分配到每个SP，根据线程的数量，每个线程可以使用几个到几时个寄存器。<br>
  使用数量巨大的寄存器，原因有:</p>
<ul>
<li>延迟隐藏的需求</li>
<li>GPU寄存器特征，CPU中，指令执行完后写入寄存器中的数据会被自动写入到缓存中，然后缓存系统会广播更新多处理器机构中其他处理器的缓存，以及将数据写入到主内存。GPU中，写入到寄存器得数据会一直停留在该寄存器中，直至有新的数据写入或者当前线程执行完毕自动退出，寄存器数据被重置。<mark>这样做的原因是，由于GPU可能同时处理上千个相同指令的线程，每个线程在执行过程中某些中间计算结果只供自己所在的线程使用，所以它完全没必要写入到全局内存。例如OpenGL着色程序，通常只有最后才会将结果写回到全局内存，这些值可能是顶点着色器质性过变换的坐标值，或者像素着色器中计算出的颜色值。</mark></li>
</ul>
<h2 id="234延迟隐藏">2.3.4延迟隐藏</h2>
<p>  为了克服读写全局内存的延迟，通过一些辅助手段“隐藏”这种延迟，称为延迟隐藏。在CPU中提到单个处理器的多线程技术，当一个线程处于延迟状态，处理器自动切换到其他组处于等待执行状态的线程进行执行，这样通过使用多于处理器能够处理个数的线程数目，内存读取的延迟也能够在一定程度上隐藏。<br>
  其中GPU在这方面的改进有，一是使用能够容纳更多的等待线程。例如只有192个SP，但是可以分配最多高达2048个线程，即是说当每个时钟周期有192个线程在执行计算的时候，还可以有将近2000个线程正在从内存中获取数据，这样通过大量线程就使得大部分线程的内存或者延迟被隐藏。<br>
  CPU多线程技术的另一个瓶颈来源于少量的寄存器。<mark>虽然每个时钟周期可以容纳多个线程处于延迟状态，但是由于寄存器数量不足，这些线程的数据被放入在缓存系统中，使得每次切换线程时都需要寄存器数据的换进换出，因此执行多线程就需要大量的延迟。</mark> GPU同样用到上下文切换的概念，但是因为拥有数量众多的寄存器，它致力于为每个线程都分配真实的寄存器，哪怕处于等待状态的线程，因此一次上下文调换只需要重新执行另一个寄存器组。</p>
<h2 id="235全局内存访问的合并">2.3.5全局内存访问的合并</h2>
<p>  并行计算的性能，还可以得益于其程序和数据的一致性，一致性越高，能够实现的吞吐率就越高，反之数据的存储越发散，将导致更低的吞吐率。<br>
  GPU使用一种称为内存合并的计数来充分利用并行程序的数据连续性。<mark><strong>当连续的线程向全局内存发起数据请求，并且请求的内存块是连续对齐时，这些线程的多个内存请求会被合并成一次请求，然后一次性返回所有数据。内存合并使得多个线程的内存请求只需要一个存储事务即可解决问题。</strong></mark><br>
  要想获得内存合并，每个线程访问的数据必须数据对齐，否则不能获得内存合并的好处。</p>
<h3 id="2351分支">2.3.5.1分支</h3>
<p>  GPU不是为了执行串行代码而设计的，为了高效执行大量的并行计算，GPU并没有像CPU那么复杂的硬件实现的分支预测功能，需要程序员小心地处理。<strong>这样导致的结果是，当程序中包含分支指令是，如果咋一个线程束内的分支分布是不连续的，将导致在处理分支的时候部分线程处于空闲状态，不能充分利用GPU的计算资源。更糟糕的是，这种由于分支导致的线程并不会导致处理器将计算资源切换到其他线程束执行，即是说，由于分支导致的部分线程的限制并不能算作线程阻塞，只有内存读取的延迟才能促使线程切换。</strong><br>
  对于分支指令，最有效的方法是尽量保证分支的连续性，对于所有线程组成的条件数组排序，或者以某种方式的处理，使得分支能够连续排列。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《全局光照技术》笔记第一章-光与表面的交互之PBR]]></title>
        <id>https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-yi-zhang-zhi-pbr</id>
        <link href="https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-yi-zhang-zhi-pbr">
        </link>
        <updated>2020-02-03T12:14:44.000Z</updated>
        <summary type="html"><![CDATA[<p>全局光照中PBR的相关知识</p>
]]></summary>
        <content type="html"><![CDATA[<p>全局光照中PBR的相关知识</p>
<!-- more -->
<h4 id="物理上正确主要是指光在场景中的传输保持能量守恒"><mark><strong>物理上正确，主要是指光在场景中的传输保持能量守恒</strong></mark></h4>
<h2 id="双向反射分布函数brdf">双向反射分布函数(BRDF)</h2>
<p>  表示反射方向上的辐射亮度增量与入射方向辐射照度增量的比率。直观上讲，BRDF的值表示入射光方向单位立体角的能量在反射方向上反射的比率。它本质上指明了每个方向的入射光在各个方向上的反射光分布。</p>
<h3 id="菲涅尔公式">菲涅尔公式</h3>
<p>  <mark>当光由一种介质进入另一种不同的介质，在光滑表面发生反射和折射时，入射光被反射和折射的比率分别是多少，这就是菲涅尔方程描述的问题。</mark> 菲涅尔公式仅取决于入射角以及两种介质的折射系数。因为原始菲涅尔公式非常复杂，在渲染领域我们通常使用Schlick提出的一种比较简单且相对比较精确的模型。<br>
使用这个模型，只取决于入射光垂直于表面时的菲涅尔反射率的值，这个值我们可以在现实生活中找到大量物质的对应值，此外也可以通过材质的折射率得出。</p>
<h3 id="微面元理论微平面理论">微面元理论(微平面理论)</h3>
<p>  我们看到的绝大部分物质在一个像素的观察尺度上都不是绝对光滑的，这个尺度为微观尺度。在微观尺度下，一个像素接收到来自某个方向的光照并不是一单束光，由于一个像素的尺寸远远大于光子的尺寸，因此入射光实际上是很多束光，这些光与微观上具有不同方向法线的微面元交互，从而反射或者折射至不同的方向。<mark><strong>由于这种微观结构不能通过分析的方式精确模拟，因此只能通过统计的方式来模拟这种微观结构的分布</strong></mark><br>
  <strong>只有那些满足反射方向刚好在观察方向v的面元才能被看到，意味着这些可以被观察的面元的法线正好位于入射方向I和观察方向v的中间，这个矢量称为<mark>半矢量(half vector)</mark> h = (l+v)/|l+v|</strong>。<br>
  基于微面元的假设和理论，基于微面元理论的BRDF模型主要有这两部分因素决定:</p>
<ul>
<li>一个关于所欲微观面元的表面法线分布函数D，<mark>其中只有法线指向半矢量h方向的面元才会被观察到</mark>。</li>
<li>对法线方向处于半矢量h的微观面元，<mark>当且仅当他们在入射方向和观察方向没有被其他面元阻挡才能被观察到</mark>，因此需要一个表示几何遮挡关系的函数G。</li>
<li>再结合菲涅尔公式F</li>
</ul>
<h3 id="微观面元法线分布函数d">微观面元法线分布函数D</h3>
<p>  BRDF最重要的部分就是微观面元的法线分布函数NDF，它是表面的微观几何结构中，所有微观面的法线面向不同方向的概率，决定了光泽部分的宽度、形状以及其他特征。<strong>根据微观面理论的假设，这个法线分布函数是由表面的粗糙度决定的。</strong> 关于光泽BRDF球状分布，<mark>它具有一个很长的拖尾</mark>，这个拖尾比一般的光泽模型要长好几倍，传统的Blinn Phong和Gaussian分布都不能有效第表达这种拖尾效应。<br>
  Disney发现只有GGX分布具有最长的拖尾，一些研究表明单一的光泽叶分布通常不能精确地描述真实物质的光泽属性，建议使用多个光泽叶，Disney叶采用了两个GGX的组合俩表述这种更长的拖尾。<br>
  对于粗糙度，Disney选择使用 a = roughness平方 以产生一个更线性的变化，这使得设计师能够更直观地调整效果。</p>
<h3 id="微观面元集合遮挡函数g">微观面元集合遮挡函数G</h3>
<p>  G称为双向阴影遮挡函数，<mark>描述的是那些具有半矢量法线的微观面元中，有多少比例是同时被入射方向和反射方向看见的(或者说没有被阻挡的)。</mark></p>
<h3 id="漫反射brdf">漫反射BRDF</h3>
<p>  出于性能考虑，工业中比较流行的方案是朗伯BRDF(Lambert BRDF)，即光从各个方向以相同的亮度反射。Lambert漫反射模型假设折射进入表面内部的光经历了足够多的散射，因此失去了方向性，从而在各个方向的反射率为一个常数。</p>
<h2 id="材质模型">材质模型</h2>
<p>  在UE4中主要有4个参数和PBR材质相关，其他引擎例如Unity也差不多,分别是</p>
<ul>
<li>Base Color</li>
<li>Roughness</li>
<li>Metallic</li>
<li>Specular</li>
</ul>
<h4 id="base-color">Base Color</h4>
<p>  BaseColor，或者更一般说法是Diffuse，代表物体表面的真实颜色。<br>
  <mark><strong>任务物体在没有光照的时候都是看不见的，可以说一个物体本身是不具备任何“颜色”的(自发光物体除外),着色的过程是将光照射到物体表面，从而计算物体表面呈现的颜色的过程。</strong></mark><br>
  光与物体表面交互分为两种方式:<strong>(Specular)光泽反射和(Diffuse)漫反射(这里仅讨论绝缘体)。</strong><br>
  <mark><strong>对于光泽反射,它的反射率的RGB分量是一样的,即它不会改变入射光的颜色，仅改变其亮度。因此光泽反映的是光源本身，例如一个白色点光源在物体表面光泽部分看到的仍然是一个白色的(亮度被菲涅尔反射率缩放)小圆点形状，使用环境贴图作为光源则会在物体表面“印上”周围的环境。所以光泽反射几乎与物体表面的真实颜色无关。</strong></mark><br>
  <mark><strong>对于漫反射，它指的是光折射进物体内部，在物体内部经历一定的散射后重新从表面散射回原来的介质。由于散射的光失去了方向性，所以我们用一个固定的反射率常数来表示这个BRDF反射率，即baseColor。所以我们所说的物体表面的“真实颜色”,其实是一个反射率，它表示当其他光照在表面进行漫反射是，在每个方向的反射率是多少，如果我们使用白色光源照亮物体表面，则物体呈现baseColor的颜色，使用其他颜色的光源则呈现其他不同的颜色(由光源颜色与baseColor的乘积决定),所以baseColor反应的就是物体在白色光照下表面的真实颜色。</strong></mark></p>
<h4 id="roughness">Roughness</h4>
<p>  <mark>控制材质的粗糙度，越粗糙的表面，入射光越向更多的方向反射(菲涅尔反射率越低，更多光被吸收形成漫反射)，物体的表面越来越接近BaseColor的颜色；反之，光泽部分越来越窄，物体表面越来越光滑，高亮度的光泽使得物体表面越来越多地反射着周围的环境(或者光源的形状)。</mark> 当Roughness为0时表示物体表面绝对光滑，成镜面反射，如果光源为点光源，镜面反射使得物体表面能够清楚看到点光源的形状及颜色，如果光源为环境贴图，则光滑物体表面能够清晰地反映出周围环境；当Roughness为1时，物体表面完全漫反射，呈现BaseColor颜色。</p>
<h4 id="metallic">Metallic</h4>
<p>  控制表面的“金属感”，金属和非金属是一个非此即彼的概念，非金属的Metiallic值为0，而对于金属表面的Metallic值为1.对于纯净的物质，例如纯净的金属，石头，塑料凳，这些材质的Metallic值要么为0，有么为1。但是另外一些混合物质，如腐蚀的物体或者布满灰尘或生锈的金属，这些材质的Metallic可能需要介于0到1之间，对于这些介于0和1之间的材质，UE通过层级纹理实现两种材质之间的混合。<mark>材质可以分为金属和非金属，而金属对于折射进表面内部的光全部吸收，从而使金属材质将不会有光从表面内部再散射回来，<strong>因此金属材质没有漫反射部分。</strong></mark> 所以在Disney的BRDF模型中，他们对金属材质去掉漫反射部分，并使用BaseColor的值作为光泽的入射光进行计算。由于这种特殊的计算方式，Metallic属性没有一个线性的计算公式，因此大部分解决方案都是使用混合的方式实现0和1之外的插值。</p>
<h4 id="specular">Specular</h4>
<p>  Specular表示入射光被反射的量，或者说反射率。需要注意的是，对于非金属而言，他们的反射率往往与波长无关，即他们RGB的分量相同，因此他们对于光泽的反射，仅影响入射光的亮度，而通常不会影响其颜色。但是金属的反射率通常和波长是相关的，它对于入射光不同的颜色分量具有不同的反射率。</p>
<h2 id="双向散射分布函数">双向散射分布函数</h2>
<p>  BRDF通过少量几个参数就能够表述比较广泛的材质，单身对于折射，次表面散射需要用特别的方法处理。这些方法通常不能保证能量守恒，因此当整个渲染器是基于光线追踪计数计算光照时，这种能量的不守恒将被放大导致真个图像品质失真。<br>
  <mark>更为一般的双向散射分布函数(BSDF),它其实是BRDF和BTDF的总和。</mark> <strong>BTDF全称为双向折射分布函数</strong>，它和BRDF的形式基本一样，唯一的区别是BTDF的观察方向是在折射方向范围内。<br>
  <mark>这样，BSDF表示，给定某点的入射方向和出射方向，出射方向上辐射亮度增量和入射方向辐射照度增量的比率。</mark></p>
<h4 id="双向折射分布函数btdf">双向折射分布函数(BTDF)</h4>
<p>  工业中比较流行的模型是Bruce Walter提出的模型。这个模型同样基于微平面理论，即宏观表面有多个微观面元组成，每个面元绝对光滑，<strong><mark>光的折射遵循折射定理</mark></strong>。折射定理不仅描述光在折射时的弯曲现象，它也间接地约束了光在折射方向发散的范围。</p>
<h4 id="次表面散射">次表面散射</h4>
<p>  传统的BRDF模型并不包括对次表面散射的计算，即光从一个点进入表面内部，经过一定散射之后从另一个点散射回原介质。但是也包含了一般的漫反射之外的一些特性，主要是回射反射效果。Disney将原有的漫反射公式拆分为两部分：一部分是与微观结构有关的具有方向性的效果(回射反射),另一部分是与方向无关的一般的漫反射效果。这样当材质次表面散射的入射点和出射点距离小于一个像素尺寸是，还是使用原来的模型，当大于一个像素尺寸是，则使用新的BSSRDF模型替换与方向无关的部分漫反射。</p>
<h4 id="超薄表面的渲染">超薄表面的渲染</h4>
<p>  对于超薄表面，Disney假设他散射的入射点和出射点位于同一点，和固体物体一样，仍然使用specTrans参数在完全漫反射和完全光泽(包括反射和折射)之间混合。</p>
<h2 id="渲染方程">渲染方程</h2>
<pre><code class="language-math">光从x向方向w_o发射的辐射亮度 = 光源或者自发光在x处沿w_o的辐射亮度 + x处沿w_o防线的来自反射/折射的辐射亮度
</code></pre>
<p>通常反射/折射的辐射亮度需要对点x法线方向的半空间进行积分。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《全局光照技术》笔记第一章-光与表面的交互]]></title>
        <id>https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-yi-zhang</id>
        <link href="https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-yi-zhang">
        </link>
        <updated>2020-02-03T12:04:10.000Z</updated>
        <summary type="html"><![CDATA[<p>介绍全局光照的基础概念</p>
]]></summary>
        <content type="html"><![CDATA[<p>介绍全局光照的基础概念</p>
<!-- more -->
<h2 id="11全局光照总览">1.1全局光照总览</h2>
<p>  主要介绍了全局光包含的几个大的方面，形成总体的认识。包括了以下几个方面。</p>
<ol>
<li>阴影。包括软阴影、硬阴影，应该是ShadowMap</li>
<li>环境遮蔽(AO)。主要增加考虑遮挡关系，使得阴影处的渲染更加逼真自然。一般离线生成，SSAO</li>
<li>反射。使用IBL采样Cubemap</li>
<li>间接光照。是全局光照最重要的部分，有各种技术，IBL，LightMap,</li>
<li>求谐光照(SH),LightProbe等等</li>
<li>焦散</li>
<li>散射</li>
</ol>
<h2 id="12辐射度量学">1.2辐射度量学</h2>
<ol>
<li>立体角。2d角度概念在3d的延伸,表示在3d空间中，从某个点观察，另一个物体有多“大”；以可以理解为3D空间中以某一点为起点的多个方向集合。通常使用单位球上一块区域面积大小来表示其对应的立体角大小。</li>
<li>辐射能量。基本单位</li>
<li>辐射亮度。从面A的一部分射出的光能量，是我们渲染方程最终要计算得值。计算的是单束光的量度。</li>
<li>辐射强度。面积A在某个方向上的辐射强度。</li>
<li>辐射照度（Irradiance）。一个点接收的来自各个方向的辐射亮度，表示表面的一个点接收的所有光照。LightMap中存储的就是辐射照度。</li>
</ol>
<h2 id="13-物体的表面着色">1.3 物体的表面着色</h2>
<ol>
<li>两种光学模型，波动光学与几何光学。波动光学由于以光的波长为测量尺寸，大大超出了计算机图形学的需求，所以计算机图形学中主要以几何光学作为光学模型。几何光学作出了几个假设:</li>
</ol>
<ul>
<li>物体表面绝对光滑</li>
<li>光仅可以被发射，反射或者传播</li>
<li>光以无限快的速度沿直线传播<br>
从以上几个假设下，反射有反射定律决定。</li>
</ul>
<ol start="2">
<li>光与表面的交互过程可以被以下描述：</li>
</ol>
<pre><code>graph LR
光源--&gt;与物体进行交互,部分被反射,部分被吸收并经过一定路径传播后沿其他方向从物体表面散射--&gt;被感应器接收形成图像
</code></pre>
<ol start="3">
<li>光源可以简单分为平行光，点光源，聚光灯</li>
<li>材质决定物体表面与光交互的一切。一般假设表面是绝对光滑的，但是实际情况是物体表面在一个像素尺度上，是不光滑的。<br>
在图形学中，材质可以分为两大类：<strong>金属与非金属</strong></li>
</ol>
<ul>
<li>金属：立即吸收所有折射的光照</li>
<li>非金属：折射光照在物体内部传播并根据物体属性在沿某个方向离开物体<br>
<strong>这种由物体内部发射回来的光通常不具有固定的方向性，所以这种反射成为漫反射(scattering)</strong><br>
在计算机图形学中，通常将反射和漫反射区分开，分别称为光泽(Specular)和漫反射(Diffuse)。</li>
<li><strong>Specular</strong>:光在物体表面的直接反射形成</li>
<li><strong>Diffuse</strong>:光进入物体表面，经过折射，吸收，多次散射过程之后重新从物体表面散射回表面外的光形成。漫反射光可以接受来自全部方向的光，因此需要对全空间进行积分计算，但是将与方向无关的部分分离，可以使用更简单的方法处理</li>
</ul>
<ol start="5">
<li>感应器如摄像机接受图像后会进行光栅化，但是会引起锯齿，这是由于采样不足导致的走样现象，相应有避免这种现象的反走样技术。</li>
</ol>
<h2 id="14-采样和反走样">1.4 采样和反走样</h2>
<p><strong>3D图像生成的本质是对各种连续函数(几何图形,BRDF分布函数)的采样,然后转化为对应的离散函数的过程。大部分采样发生在光栅化阶段。</strong></p>
<ol>
<li><strong>傅里叶变换</strong>：任何非周期的连续函数可以用正弦和/余弦和乘以一个加权函数的积分来表示，这个积分方程为傅里叶变换。傅里叶变换将一个连续非周期函数由其时间域或者空间域变换到其频率域。目的是在频率域我们可以发现该函数的一些重要特征，甚至一些对函数的操作在频率域进行更方便。</li>
<li><strong>卷积</strong>：两个函数f和g,在其中一个函数翻转180°之后，两个函数乘积的积分。<br>
<strong>卷积定理</strong>：对于卷积和傅里叶变换，可以证明，空间域中两个函数的卷积的傅里叶变换等于两个函数的傅里叶变换在频率域的乘积；反过来，如果有两个变换的乘积，可以通过计算傅里叶反变换得到空间域的卷积</li>
<li><strong>采样定理</strong>：冲激函数具有采样特性，可以简单地得到冲激位置处的函数值，那么如果我们定义一个具有均匀间隔的冲激函数，将这个冲激串作用于一个连续函数，那么其结果就得到对原始信号的均匀采样。借助冲激函数的傅里叶变换和卷积定理，可以得出采样定理，进而指导我们对函数进行采样。<strong>冲激串函数的傅里叶变换仍然是一个冲激串函数</strong>。一个连续函数被采样成一个离散函数后，其能够被重建为原函数的能力取决于采样点的密度，或称为采样率。<strong>采样率必须大于等于2x最大频率采样点/秒才能够被完美复原</strong></li>
<li><strong>几何走样</strong>:</li>
</ol>
<ul>
<li><strong>光栅化本质：</strong> 按照屏幕分辨率对可见性函数进行采样，即采样点之间的间距为一个像素，采样点的位置为每个像素的中点。</li>
<li><strong>几何走样：</strong> 由于对几何图形的可见性函数采样导致的走样称为几何走样，是计算机图形学中最严重的走样现象。<mark>这是由于可见性函数是一个连续函数，想要呈现很好的图像，必须要在图像上还原出很好的原始可见性函数，根据采样定律，必须使用两倍于可见性函数最高频率的采样率。但是三角形的可见性总是存在不连续，这种不连续导致无限大的频率，从而使其傅里叶变换不存在有限的频率带宽，因此没有采样率可以阻止走样发生；同时根据傅里叶变换的条件，只有定义域在无限的时间域或者空间域才能使其傅里叶变换具有有限的频率带宽，所以对于计算机图形学中有限的二维或者三维空间域，走样现象是不可避免的</mark>。</li>
<li><strong>着色走样：</strong> 由于像素着色器受限于屏幕分辨率所限导致的。主要是指，在着色器中对一些以分析的方式得到的连续函数的采样不足导致走样，而不是对纹理的采样不足。解决思路主要是将一些外部参数融入到光照计算，如BRDF，使“原始连续函数”更加平缓，在对这些光照结果采样。</li>
<li><strong>时间走样：</strong> 由于渲染帧率的限制使其对运动过程的采样不足导致的走样。解决方法一是运动模糊，但是计算成本高；二是针对当前帧渲染结果，生成一个速率缓存，然后使用这些方向在后处理阶段对其邻近像素点进行插值计算。</li>
</ul>
<ol start="5">
<li><strong>重建</strong> 卷积计算最本质也是最直观的特征是平滑，它通过对f的每个点考虑该点周围一定范围内的值对该点的影响，来消除该点与周围环境的频率的快速变化。这在计算机图形学运用广泛，大部分可能出现走样的地方，都可以在采样之前对原始函数进行平滑，以减轻走样现象。<mark>图像处理中，卷积的意义相当于使用一个蒙版遍历每一个像素点，分别计算蒙版内所有乘积的和，GPU中纹理过滤相关技术都是通过卷积的方式实现</mark></li>
<li><strong>重采样</strong> 最近邻内插值法、双线性插值法等。</li>
<li><strong>屏幕反走样</strong> 几何走样、着色器走样都跟屏幕分辨率有关，如果能从像素着色器解决走样问题,或许就能解决所有由于分辨率带来的走样。<mark>走样是一个采样问题，不能通过任何技术手段在采样之后消除这种由于采样不足导致的走样。走样是由于采样率低导致傅里叶变换的高频部分没有被覆盖，从而使相邻的采样点之间出现较大的差异。</mark></li>
</ol>
<ul>
<li><strong>过采样/超采样</strong> 针对特定分辨率的反走样技术，通过使用一个比输出分辨率略高的采样率对原始函数进行采样并对这个高分辨率的样本函数使用滤波器进行平滑，然后对这个高分辨率的样本函数进行重采样得到输出分辨率的图像。</li>
<li><strong>FSAA(全屏反走样)</strong> 以高分辨率渲染，然后对于相邻采样点取平均值得到最终图像。优点是实现简单，缺点是计算量大，每个子采样点都需要被进行一次着色。</li>
<li><strong>MSAA(多重采样反走样)</strong> 对于每个像素生成多个子采样点，并计算每个子采样点的深度和模板值，而对于颜色值，光栅化器对每个像素只调用一次像素着色器，然后将计算结果复制给每个子采样点。<mark>由于像素着色器只计算一次，相对FSAA大大减少了计算量，但是内存占用并没有减少。</mark> 纹理采样的位置一般是使用像素中心点位置，但是在MSAA下,几何图形可能只占据像素的小部分区域并不包括中心点,这时候再使用中心点采样纹理是不正确的；为了确保颜色采样的正确性,这个像素着色器使用的采样位置可以被调整到覆盖区域中某个点的位置，这种技术称为<strong>质心采样</strong>。<mark>对于一个被几何图形覆盖的像素点，它首先从像素中心点开始寻找，如果中心点没有被几何图形覆盖，则一次向外延伸直到找到一个被覆盖的子采样点，该点的位置将作为最终像素着色器对纹理采样的位置。</mark></li>
</ul>
]]></content>
    </entry>
</feed>