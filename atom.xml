<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zanegjun.github.io</id>
    <title>ZaneGJun Blob</title>
    <updated>2020-02-04T12:15:34.597Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://zanegjun.github.io"/>
    <link rel="self" href="https://zanegjun.github.io/atom.xml"/>
    <subtitle>记录文字</subtitle>
    <logo>https://zanegjun.github.io/images/avatar.png</logo>
    <icon>https://zanegjun.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, ZaneGJun Blob</rights>
    <entry>
        <title type="html"><![CDATA[《全局光照技术》笔记第二章-并行处理器架构]]></title>
        <id>https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-er-zhang-bing-xing-chu-li-qi-jia-gou</id>
        <link href="https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-er-zhang-bing-xing-chu-li-qi-jia-gou">
        </link>
        <updated>2020-02-04T12:14:30.000Z</updated>
        <content type="html"><![CDATA[<h1 id="cpu">CPU</h1>
<h2 id="21cpu应用程序执行模型">2.1CPU应用程序执行模型</h2>
<p>  现代CPU遵循冯·诺依曼提出的处理器架构。在该结构中，一个具有处理单元的点子数字计算机由以下部分组成：</p>
<ul>
<li>一个用于进行二进制运算的算术逻辑单元(ALU)</li>
<li>一个用来告诉存储指令和数据的寄存器组</li>
<li>一个用来控制指令读取的控制单元</li>
<li>一个用于存储所有指令和数据的内存</li>
<li>外加一些大容量存储设备及输入输出设备</li>
</ul>
<p>  通常执行过程为 <mark><strong>处理器从内存中将指令和数据(包括地址)读取到寄存器并解码，然后执行该指令。</strong></mark> 因为程序和数据存储在内存中，和处理器分开，因此数据需要在内存和处理器之间进行传输。随着现代处理器运行速度提高，更多时间用于等待从内存获取数据。主要有以下几个方法用于克服这个瓶颈:</p>
<ul>
<li><strong>缓存</strong> 设计一些容量小，速度快的缓存来减少从主存取数据的时间</li>
<li><strong>预取</strong> 通过在处理器读取数据之前预测可能会读取的数据，从而提前读取到缓存中</li>
<li><strong>多线程</strong> 并发处理，主要有指令级并行、线程级并行、处理器级并行</li>
</ul>
<h3 id="211缓存">2.1.1缓存</h3>
<p>  缓存是一种容量更小，更快的内存，缓存里的数据来自于内存。处理器需要向主存或者指令或者数据是，先查询缓存，如果数据不在L1缓存中，则向L2/L3发出读取请求，如果还是没有则从主存读取。<strong>L1缓存的速度通常能达到或者接近处理器的时钟速度，因此假设写入和读取都是在L1中完成，则指令的执行很有可能接近处理器全速。</strong> L1通常只有16KB或者32KB，L2速度慢些，但是容量更大，通常256KB，L3通常几兆，但是速度最慢。<br>
  在缓存设计中，L1和L2都是每个核独享，而L3则是所有核共享。缓存的设计利用局部性原理，包括时间局部性和空间局部性。时间局部性指之前访问的数据很可能还要被再次访问；空间局部性指刚刚被访问的数据附近的数据，可能马上要被访问。注意缓存命中率与缓存失效，失效可能是第一次访问新的数据，又或者因为缓存的尺寸限制，旧的缓存被LRU给清理了。<br>
  缓存的设计是有代价的，增大缓存会增加芯片面积。</p>
<h3 id="212预取">2.1.2预取</h3>
<p>  预取是指通过在处理器读取数据之前预测可能会被读取的数据，提前读取到缓冲中。一般集成在处理器内部，各级缓存都有自己的预取器。一些编译器如GCC还通过在编译阶段修改源码，在其中插入预期指令实现软件预取。<br>
  最常用的数据预取是 <strong><mark>常数步幅模式</mark></strong>,即根据之前数据访问的模式(在一个常数范围内的步幅)预先载入当前数据邻近对应长度范围的数据。<strong>但是数据预取器不擅长对随机数据的预测</strong>。程序指令在空间上的分布更加线性，其相对数据预取更加简单。然而有以下几种情况使得程序指令出现非线性化：</p>
<ul>
<li>函数指针的应用，由于处理器只有在执行指令的时候才会知道其指令是追踪一个指针，所以指令预取器对函数指针没有办法进行预处理。</li>
<li>分支预测，分支决定只有在条件被计算出来才能发生。所以分支预测必须记录过去的历史数据，以此计算出一定的模式并度后续的分支使用该模式来预测分支走向，这就是各种不同分支预测算法的基础。</li>
</ul>
<h3 id="22并行计算架构">2.2并行计算架构</h3>
<h4 id="221指令级并行">2.2.1指令级并行</h4>
<p>  指令级并行计算称为ILP(instruction-level parallelism),指一个单处理器同时执行多条指令的能力。IPL计数允许编译器和硬件重叠地执行多个指令，或者甚至按不同的顺序执行指令。IPL对程序员是透明的。下面介绍一些比较流行的ILP技术。</p>
<h5 id="2211指令管线化">2.2.1.1指令管线化</h5>
<p>  意思是将一条指令完整的执行流程分成多个阶段，每个阶段允许一条单独的指令执行。<mark>这样的划分有一些重要的原因，处理器内部正度这些特定的阶段都有专门的计算功能，如果一次只处理一条指令，当其中任何一个阶段发生延迟或者缓存失效，都会导致其他功能除以等待空闲状态，不能充分利用处理器的资源。</mark> 一般可以分为经典的5个阶段:</p>
<ol>
<li>IF:获取指令阶段，处理器从L1获取一个32位(64位机则64位)的指令，该操作通常具有1个时钟周期的延迟。</li>
<li>ID/RF：解码指令以及从寄存器获取操作数</li>
<li>EX：执行</li>
<li>MEM：读取内存</li>
<li>WB：写回寄存器</li>
</ol>
<p>  指令管线化通过充分利用各个生产流水线，提高了整个关系的吞吐能力。然后并不能减少延迟，当指令对应阶段出现延迟，该指令将处于停止等待状态。指令管线化假设多哟指令是可以并行执行的，当程序中的指令出现依赖，我们称为一个障碍。一般有下面的方法来处理串行指令的并行障碍</p>
<ul>
<li>
<p><strong>管线气泡</strong><br>
  最简单的一种处理方式，当指令包含障碍是，其将在解码阶段被识别，同时处理器会创建一个气泡占据该指令的解码阶段，使当前管线的解码阶段处于空闲等待状态，管线气泡将导致后续一个或多个指令被延迟。</p>
</li>
<li>
<p><strong>操作数前移</strong><br>
  操作数前移中，处理器需要对指令探测这种依赖性的存在，然后根据探测结果判断是需要从寄存器获取操作数，还是直接通过相关的电路直接获取前一指令的值。</p>
</li>
<li>
<p><strong>乱序执行</strong><br>
  乱序执行基于这个的事实，即如果后面的指令不依赖前面的指令，或者说它此时具备执行指令需要的操作数据，则它可以闲鱼前面的指令被执行。然后乱序执行必须保证指令执行结果输出的顺序与程序顺序保持一致，以保证最终程序运行的正确性。</p>
</li>
<li>
<p><strong>分支预测对指令管线的影响</strong><br>
  分支预测失败会导致处理器放弃并销毁之前所有未执行完且判断错误的分支指令。因为分支的真实走向必须等到if比较指令执行完毕，并且将结果写入到寄存器之后，处理器才会知道真正的分支走向。例如有A是比较执行，BCD是错误的分支走向，只有等到A指令执行完毕才能知道分支走向的正确性，这时候BCD因为流水线的原因，会依次被执行，当A执行完毕处理器知道BCD是错误的走向，需要销毁所有关于BCD在寄存器的数据及其他状态，然后将正确的EFG指令载入执行单元执行指令计算。<br>
  如果if比较函数是对两个浮点数进行比较，代价更高，浮点数比证书的比较要花费更多的时钟周期。<br>
  现代处理大都会采用一种方法避免比较和跳转操作。这种方法基于一个第三个参数，来在两个操作数之间进行选择，而不需要执行比较和跳转指令，这称为条件转移或无分支选择。</p>
</li>
</ul>
<h4 id="222线程级并行">2.2.2线程级并行</h4>
<p>  多线程处理器内部可以支持多个线程并行执行，但是这些线程不是真正地同时执行，而是通过处理器的控制交叉地执行。当当前正在执行的线程遇到缓存失效或者其他事件，处理器即自动切换到其他处于等待执行状态的线程执行指令。<br>
  硬件对多线程支持目标是，允许在等待延迟的线程和已经准备好的被执行线程之间保持快速切换。为了这个目的，每个线程都需要拥有自己的指令和数据寄存器集合，包括用于存储指令管线调度相关的一些处理单元和跳读信息，当发现线程切换，直接在高速的寄存器之间执行赋值和读取，不需要重新从缓存读取数据。现代处理器一般在一个时钟周期内可以完成线程切换。</p>
<h5 id="2221同时多线程技术">2.2.2.1同时多线程技术</h5>
<p>  多线程有多种实现方案:</p>
<ul>
<li>最简单是块多线程(block multithreading)，这种方案会一直执行一个线程，直至线程遇到很大的延迟(如缓存失效,可能需要上百个时钟周期)时才切换到另一个处于&quot;可执行状态&quot;的线程。</li>
<li>较为聪明的方案称为交叉多线程，在每个时钟周期都使用一个不同于上一个时钟周期的线程。因为线程间是相对独立的，每次从不同的线程取出一条指令加入到指令管线，这样理想的情况下指令管线中每个阶段执行的是不同线程中的指令，从而几乎不会有数据依赖关系。但是缺点是每个指令阶段都需要额外的计算和存储成本用来追踪这些线程ID。</li>
</ul>
<p>  上面两种都可以称为时分多线程技术(TMT),对于给定的任何时间，指令管线的每个阶段只有一个线程的指令在执行。而现代处理器比较高级的多线程技术方案是同时多线程技术(SMT)，在一个给定的时间内及指令阶段，SMT处理器可以同时又来自多个线程的指令在执行。</p>
<h4 id="223处理器级并行">2.2.3处理器级并行</h4>
<p>  多处理器架构是指一个计算机系统拥有多个物理额处理器或者拥有多个核，区别为多喝处理器每个核仅拥有L1缓存及寄存器，统一芯片内的核共享L2及主存，而多个单独的物理处理器仅共享主存并拥有自己的缓存系统。</p>
<h5 id="2231多核处理器架构的对等性">2.2.3.1多核处理器架构的对等性</h5>
<p>  对称性指所有处理器的地位和功能是否对等，非对等处理器机构比较典型是Cell处理器架构，思想是用一个常规处理器作为监管处理器，该处理器与大量的告诉协作处理器相连。它跟GPU很像，它独特之处在于摒弃了传统的内存缓存结构，直接将数据和指令直接发送到每个协作处理器的私有内存，让它一次性尽可能做更多计算。协作处理器主要聚焦于数据密集型计算。处理器中，缓存系统占据了很多芯片面积，并且导致能耗增加。这种设计结构能大大减少芯片面积及能耗。</p>
<h5 id="2232多处理器架构的通信方式">2.2.3.2多处理器架构的通信方式</h5>
<p>  多处理器架构可以分为共享内存以及基于网络的消息传递方式。<br>
  共享内存中，每个处理器有自己的缓存系统，但是他们共享整个计算机系统的主内存。需要注意的是缓存一致性问题，这是限制一个处理器中核数不能太多的一个重要因素。<br>
  另一种多处理器架构称为集群，通过将一些独立的通常是廉价的计算机系统，通过网络等方式联通起来，组成一个多处理器系统。适合于线程之间的耦合相对比较弱的计算。</p>
<h1 id="gpu">GPU</h1>
<h2 id="231为什么需要一个并行计算架构">2.3.1为什么需要一个并行计算架构</h2>
<p>  一般的多处理器机构执行大规模并行计算的限制来源于针对串行计算优化的缓存系统。高速缓存系统的成本非常高，并且占用芯片很大面积，操作数从主内存到ALU之间的传输需要耗费大量的电能。这些因素使得基于缓存的处理器系统很难扩张以应付大规模的并行计算。</p>
<h2 id="232内存结构">2.3.2内存结构</h2>
<p>  GPU使用一种称为程序托管的内存模型，即数据额存放地点由程序员决定，因此它要求程序员需要对GPU内存结构有一定了解。而CPU使用一种称为硬件托管的内存模型，缓存会自动根据局部性特征获取当前正在执行指令附近的指令以及当前正在处理数据附近的数据，并在指令将计算结果写入到寄存器之后自动将其写入到缓存系统，以及更新多处理器架构中其他处理器的缓存，一切都是硬件自动完成。<br>
  <img src="https://raw.githubusercontent.com/ZaneGJun/PictureWarehouse/master/2.12_min.JPG" alt="image" loading="lazy"><br>
  上图所示是NIVIDIA的一个GPU内存结构，其中流处理器族(Stream multiprocessor,SM)相当于一个CPU核，每个SM内部有多个流处理器(Stream processor,SP)，每个SP用于执行并行计算 中的一个独立的线程。<br>
  GPU中的内存分为4种:</p>
<ol>
<li>寄存器</li>
<li>共享内存</li>
<li>常量/纹理内存</li>
<li>全局内存</li>
</ol>
<table>
<thead>
<tr>
<th>存储类型</th>
<th>带宽</th>
<th>延迟</th>
</tr>
</thead>
<tbody>
<tr>
<td>寄存器</td>
<td>约8TB/s</td>
<td>1个周期</td>
</tr>
<tr>
<td>共享内存</td>
<td>约1.5TB/s</td>
<td>1-32个周期</td>
</tr>
<tr>
<td>纹理/常量内存</td>
<td>约200MB/s</td>
<td>400-600个周期</td>
</tr>
<tr>
<td>全局内存</td>
<td>约200MB/s</td>
<td>400-600个周期</td>
</tr>
</tbody>
</table>
<h3 id="2321全局内存">2.3.2.1全局内存</h3>
<p>  GPU拥有自己独立的内存，所以宿主程序需要将数据从CPU传输到GPU以计算。通常GPU设备都是通过PCI-E总线与处理器相连，目前PCI-E 3.0 的传输率为8G/s。<br>
  <mark>GPU中的主内存称为全局内存，这是因为GPU和CPU都能对其进行写操作。宿主程序要想在GPU上执行计算，首先将CPU中的数据和指令通过PCI-E总线传输至GPU的全局内存中，接着GPU中的各个内核线程从全局内存中读取数据并执行计算，然后将计算结果写回到全局内存，最后宿主程序再从GPU全局内存中读取数据回CPU。</mark><br>
  数据从CPU传到GPU全局内存以及全局内存到CPU内核函数的寄存器之间的传输都会产生大量的延迟。<strong>全局内存是GPU中内核函数访问最慢的内存</strong>，由于GPU使用程序托管的内存模型，所以内核函数可以选择不需要将每个变量的中间结果都写回到全局内存，这些中间数据可以保存在内核函数所在的执行单元本地，而等到内核函数执行完毕才将本地的数据写回到全局内存。这大大节省了数据在全局内存和内核函数之间的不必要的传输时间。</p>
<h3 id="2322常量纹理内存">2.3.2.2常量/纹理内存</h3>
<p>  常量/纹理内存其实只是全局内存的一种虚拟地址形式，GPU并没有特殊保留的常量/纹理内存，但是常量/纹理内存能够提供高速缓存，此外它们都是只读内存。常量内存合一被缓存到常量内存缓存存储器，纹理内存可以被缓存到纹理内存缓存存储器，这些存储器通常都是L1级缓存，可以提供较全局内存更快的访问速度。<br>
  对于纹理内存，它提供基于硬件的线性插值功能。</p>
<h3 id="2323共享缓存">2.3.2.3共享缓存</h3>
<p>  由前面可知，内核函数的多个线程会被分配到多个SM上执行，据此我们可以对并行计算处理的数据进行一定的划分成多个处理子块，在每个子块内部的多个线程可以共享一些局部数据。这些单个SM内部的局部数据不需要通过缓慢的全局内存进行存储和读取，它们可以被存储在一个SM内部的共享内存中。<br>
  为了提供更高的带宽，共享内存使用的是基于存储器切换的架构，它将共享内存平均分成多个尺寸相同的内存模块，称为存储体，这些存储体内部的孽畜可以被同时使用。任何对共享内存度或者写的操作可以均分到n个不同的存储体地址，每个存储体地址都可以被同时访问，使其可以提供相对于单个内存模块n被带宽。<br>
  但是需要注意的是可能会有存储体冲突。</p>
<h3 id="2324寄存器">2.3.2.4寄存器</h3>
<p>  GPU的每个SM拥有一个巨大的寄存器文件，它通常包含上千个寄存器，这些寄存器平均分配到每个SP，根据线程的数量，每个线程可以使用几个到几时个寄存器。<br>
  使用数量巨大的寄存器，原因有:</p>
<ul>
<li>延迟隐藏的需求</li>
<li>GPU寄存器特征，CPU中，指令执行完后写入寄存器中的数据会被自动写入到缓存中，然后缓存系统会广播更新多处理器机构中其他处理器的缓存，以及将数据写入到主内存。GPU中，写入到寄存器得数据会一直停留在该寄存器中，直至有新的数据写入或者当前线程执行完毕自动退出，寄存器数据被重置。<mark>这样做的原因是，由于GPU可能同时处理上千个相同指令的线程，每个线程在执行过程中某些中间计算结果只供自己所在的线程使用，所以它完全没必要写入到全局内存。例如OpenGL着色程序，通常只有最后才会将结果写回到全局内存，这些值可能是顶点着色器质性过变换的坐标值，或者像素着色器中计算出的颜色值。</mark></li>
</ul>
<h2 id="234延迟隐藏">2.3.4延迟隐藏</h2>
<p>  为了克服读写全局内存的延迟，通过一些辅助手段“隐藏”这种延迟，称为延迟隐藏。在CPU中提到单个处理器的多线程技术，当一个线程处于延迟状态，处理器自动切换到其他组处于等待执行状态的线程进行执行，这样通过使用多于处理器能够处理个数的线程数目，内存读取的延迟也能够在一定程度上隐藏。<br>
  其中GPU在这方面的改进有，一是使用能够容纳更多的等待线程。例如只有192个SP，但是可以分配最多高达2048个线程，即是说当每个时钟周期有192个线程在执行计算的时候，还可以有将近2000个线程正在从内存中获取数据，这样通过大量线程就使得大部分线程的内存或者延迟被隐藏。<br>
  CPU多线程技术的另一个瓶颈来源于少量的寄存器。<mark>虽然每个时钟周期可以容纳多个线程处于延迟状态，但是由于寄存器数量不足，这些线程的数据被放入在缓存系统中，使得每次切换线程时都需要寄存器数据的换进换出，因此执行多线程就需要大量的延迟。</mark> GPU同样用到上下文切换的概念，但是因为拥有数量众多的寄存器，它致力于为每个线程都分配真实的寄存器，哪怕处于等待状态的线程，因此一次上下文调换只需要重新执行另一个寄存器组。</p>
<h2 id="235全局内存访问的合并">2.3.5全局内存访问的合并</h2>
<p>  并行计算的性能，还可以得益于其程序和数据的一致性，一致性越高，能够实现的吞吐率就越高，反之数据的存储越发散，将导致更低的吞吐率。<br>
  GPU使用一种称为内存合并的计数来充分利用并行程序的数据连续性。<mark><strong>当连续的线程向全局内存发起数据请求，并且请求的内存块是连续对齐时，这些线程的多个内存请求会被合并成一次请求，然后一次性返回所有数据。内存合并使得多个线程的内存请求只需要一个存储事务即可解决问题。</strong></mark><br>
  要想获得内存合并，每个线程访问的数据必须数据对齐，否则不能获得内存合并的好处。</p>
<h3 id="2351分支">2.3.5.1分支</h3>
<p>  GPU不是为了执行串行代码而设计的，为了高效执行大量的并行计算，GPU并没有像CPU那么复杂的硬件实现的分支预测功能，需要程序员小心地处理。<strong>这样导致的结果是，当程序中包含分支指令是，如果咋一个线程束内的分支分布是不连续的，将导致在处理分支的时候部分线程处于空闲状态，不能充分利用GPU的计算资源。更糟糕的是，这种由于分支导致的线程并不会导致处理器将计算资源切换到其他线程束执行，即是说，由于分支导致的部分线程的限制并不能算作线程阻塞，只有内存读取的延迟才能促使线程切换。</strong><br>
  对于分支指令，最有效的方法是尽量保证分支的连续性，对于所有线程组成的条件数组排序，或者以某种方式的处理，使得分支能够连续排列。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《全局光照技术》笔记-第一章之PBR]]></title>
        <id>https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-yi-zhang-zhi-pbr</id>
        <link href="https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-yi-zhang-zhi-pbr">
        </link>
        <updated>2020-02-03T12:14:44.000Z</updated>
        <summary type="html"><![CDATA[<p>全局光照中PBR的相关知识</p>
]]></summary>
        <content type="html"><![CDATA[<p>全局光照中PBR的相关知识</p>
<!-- more -->
<h4 id="物理上正确主要是指光在场景中的传输保持能量守恒"><mark><strong>物理上正确，主要是指光在场景中的传输保持能量守恒</strong></mark></h4>
<h2 id="双向反射分布函数brdf">双向反射分布函数(BRDF)</h2>
<p>  表示反射方向上的辐射亮度增量与入射方向辐射照度增量的比率。直观上讲，BRDF的值表示入射光方向单位立体角的能量在反射方向上反射的比率。它本质上指明了每个方向的入射光在各个方向上的反射光分布。</p>
<h3 id="菲涅尔公式">菲涅尔公式</h3>
<p>  <mark>当光由一种介质进入另一种不同的介质，在光滑表面发生反射和折射时，入射光被反射和折射的比率分别是多少，这就是菲涅尔方程描述的问题。</mark> 菲涅尔公式仅取决于入射角以及两种介质的折射系数。因为原始菲涅尔公式非常复杂，在渲染领域我们通常使用Schlick提出的一种比较简单且相对比较精确的模型。<br>
使用这个模型，只取决于入射光垂直于表面时的菲涅尔反射率的值，这个值我们可以在现实生活中找到大量物质的对应值，此外也可以通过材质的折射率得出。</p>
<h3 id="微面元理论微平面理论">微面元理论(微平面理论)</h3>
<p>  我们看到的绝大部分物质在一个像素的观察尺度上都不是绝对光滑的，这个尺度为微观尺度。在微观尺度下，一个像素接收到来自某个方向的光照并不是一单束光，由于一个像素的尺寸远远大于光子的尺寸，因此入射光实际上是很多束光，这些光与微观上具有不同方向法线的微面元交互，从而反射或者折射至不同的方向。<mark><strong>由于这种微观结构不能通过分析的方式精确模拟，因此只能通过统计的方式来模拟这种微观结构的分布</strong></mark><br>
  <strong>只有那些满足反射方向刚好在观察方向v的面元才能被看到，意味着这些可以被观察的面元的法线正好位于入射方向I和观察方向v的中间，这个矢量称为<mark>半矢量(half vector)</mark> h = (l+v)/|l+v|</strong>。<br>
  基于微面元的假设和理论，基于微面元理论的BRDF模型主要有这两部分因素决定:</p>
<ul>
<li>一个关于所欲微观面元的表面法线分布函数D，<mark>其中只有法线指向半矢量h方向的面元才会被观察到</mark>。</li>
<li>对法线方向处于半矢量h的微观面元，<mark>当且仅当他们在入射方向和观察方向没有被其他面元阻挡才能被观察到</mark>，因此需要一个表示几何遮挡关系的函数G。</li>
<li>再结合菲涅尔公式F</li>
</ul>
<h3 id="微观面元法线分布函数d">微观面元法线分布函数D</h3>
<p>  BRDF最重要的部分就是微观面元的法线分布函数NDF，它是表面的微观几何结构中，所有微观面的法线面向不同方向的概率，决定了光泽部分的宽度、形状以及其他特征。<strong>根据微观面理论的假设，这个法线分布函数是由表面的粗糙度决定的。</strong> 关于光泽BRDF球状分布，<mark>它具有一个很长的拖尾</mark>，这个拖尾比一般的光泽模型要长好几倍，传统的Blinn Phong和Gaussian分布都不能有效第表达这种拖尾效应。<br>
  Disney发现只有GGX分布具有最长的拖尾，一些研究表明单一的光泽叶分布通常不能精确地描述真实物质的光泽属性，建议使用多个光泽叶，Disney叶采用了两个GGX的组合俩表述这种更长的拖尾。<br>
  对于粗糙度，Disney选择使用 a = roughness平方 以产生一个更线性的变化，这使得设计师能够更直观地调整效果。</p>
<h3 id="微观面元集合遮挡函数g">微观面元集合遮挡函数G</h3>
<p>  G称为双向阴影遮挡函数，<mark>描述的是那些具有半矢量法线的微观面元中，有多少比例是同时被入射方向和反射方向看见的(或者说没有被阻挡的)。</mark></p>
<h3 id="漫反射brdf">漫反射BRDF</h3>
<p>  出于性能考虑，工业中比较流行的方案是朗伯BRDF(Lambert BRDF)，即光从各个方向以相同的亮度反射。Lambert漫反射模型假设折射进入表面内部的光经历了足够多的散射，因此失去了方向性，从而在各个方向的反射率为一个常数。</p>
<h2 id="材质模型">材质模型</h2>
<p>  在UE4中主要有4个参数和PBR材质相关，其他引擎例如Unity也差不多,分别是</p>
<ul>
<li>Base Color</li>
<li>Roughness</li>
<li>Metallic</li>
<li>Specular</li>
</ul>
<h4 id="base-color">Base Color</h4>
<p>  BaseColor，或者更一般说法是Diffuse，代表物体表面的真实颜色。<br>
  <mark><strong>任务物体在没有光照的时候都是看不见的，可以说一个物体本身是不具备任何“颜色”的(自发光物体除外),着色的过程是将光照射到物体表面，从而计算物体表面呈现的颜色的过程。</strong></mark><br>
  光与物体表面交互分为两种方式:<strong>(Specular)光泽反射和(Diffuse)漫反射(这里仅讨论绝缘体)。</strong><br>
  <mark><strong>对于光泽反射,它的反射率的RGB分量是一样的,即它不会改变入射光的颜色，仅改变其亮度。因此光泽反映的是光源本身，例如一个白色点光源在物体表面光泽部分看到的仍然是一个白色的(亮度被菲涅尔反射率缩放)小圆点形状，使用环境贴图作为光源则会在物体表面“印上”周围的环境。所以光泽反射几乎与物体表面的真实颜色无关。</strong></mark><br>
  <mark><strong>对于漫反射，它指的是光折射进物体内部，在物体内部经历一定的散射后重新从表面散射回原来的介质。由于散射的光失去了方向性，所以我们用一个固定的反射率常数来表示这个BRDF反射率，即baseColor。所以我们所说的物体表面的“真实颜色”,其实是一个反射率，它表示当其他光照在表面进行漫反射是，在每个方向的反射率是多少，如果我们使用白色光源照亮物体表面，则物体呈现baseColor的颜色，使用其他颜色的光源则呈现其他不同的颜色(由光源颜色与baseColor的乘积决定),所以baseColor反应的就是物体在白色光照下表面的真实颜色。</strong></mark></p>
<h4 id="roughness">Roughness</h4>
<p>  <mark>控制材质的粗糙度，越粗糙的表面，入射光越向更多的方向反射(菲涅尔反射率越低，更多光被吸收形成漫反射)，物体的表面越来越接近BaseColor的颜色；反之，光泽部分越来越窄，物体表面越来越光滑，高亮度的光泽使得物体表面越来越多地反射着周围的环境(或者光源的形状)。</mark> 当Roughness为0时表示物体表面绝对光滑，成镜面反射，如果光源为点光源，镜面反射使得物体表面能够清楚看到点光源的形状及颜色，如果光源为环境贴图，则光滑物体表面能够清晰地反映出周围环境；当Roughness为1时，物体表面完全漫反射，呈现BaseColor颜色。</p>
<h4 id="metallic">Metallic</h4>
<p>  控制表面的“金属感”，金属和非金属是一个非此即彼的概念，非金属的Metiallic值为0，而对于金属表面的Metallic值为1.对于纯净的物质，例如纯净的金属，石头，塑料凳，这些材质的Metallic值要么为0，有么为1。但是另外一些混合物质，如腐蚀的物体或者布满灰尘或生锈的金属，这些材质的Metallic可能需要介于0到1之间，对于这些介于0和1之间的材质，UE通过层级纹理实现两种材质之间的混合。<mark>材质可以分为金属和非金属，而金属对于折射进表面内部的光全部吸收，从而使金属材质将不会有光从表面内部再散射回来，<strong>因此金属材质没有漫反射部分。</strong></mark> 所以在Disney的BRDF模型中，他们对金属材质去掉漫反射部分，并使用BaseColor的值作为光泽的入射光进行计算。由于这种特殊的计算方式，Metallic属性没有一个线性的计算公式，因此大部分解决方案都是使用混合的方式实现0和1之外的插值。</p>
<h4 id="specular">Specular</h4>
<p>  Specular表示入射光被反射的量，或者说反射率。需要注意的是，对于非金属而言，他们的反射率往往与波长无关，即他们RGB的分量相同，因此他们对于光泽的反射，仅影响入射光的亮度，而通常不会影响其颜色。但是金属的反射率通常和波长是相关的，它对于入射光不同的颜色分量具有不同的反射率。</p>
<h2 id="双向散射分布函数">双向散射分布函数</h2>
<p>  BRDF通过少量几个参数就能够表述比较广泛的材质，单身对于折射，次表面散射需要用特别的方法处理。这些方法通常不能保证能量守恒，因此当整个渲染器是基于光线追踪计数计算光照时，这种能量的不守恒将被放大导致真个图像品质失真。<br>
  <mark>更为一般的双向散射分布函数(BSDF),它其实是BRDF和BTDF的总和。</mark> <strong>BTDF全称为双向折射分布函数</strong>，它和BRDF的形式基本一样，唯一的区别是BTDF的观察方向是在折射方向范围内。<br>
  <mark>这样，BSDF表示，给定某点的入射方向和出射方向，出射方向上辐射亮度增量和入射方向辐射照度增量的比率。</mark></p>
<h4 id="双向折射分布函数btdf">双向折射分布函数(BTDF)</h4>
<p>  工业中比较流行的模型是Bruce Walter提出的模型。这个模型同样基于微平面理论，即宏观表面有多个微观面元组成，每个面元绝对光滑，<strong><mark>光的折射遵循折射定理</mark></strong>。折射定理不仅描述光在折射时的弯曲现象，它也间接地约束了光在折射方向发散的范围。</p>
<h4 id="次表面散射">次表面散射</h4>
<p>  传统的BRDF模型并不包括对次表面散射的计算，即光从一个点进入表面内部，经过一定散射之后从另一个点散射回原介质。但是也包含了一般的漫反射之外的一些特性，主要是回射反射效果。Disney将原有的漫反射公式拆分为两部分：一部分是与微观结构有关的具有方向性的效果(回射反射),另一部分是与方向无关的一般的漫反射效果。这样当材质次表面散射的入射点和出射点距离小于一个像素尺寸是，还是使用原来的模型，当大于一个像素尺寸是，则使用新的BSSRDF模型替换与方向无关的部分漫反射。</p>
<h4 id="超薄表面的渲染">超薄表面的渲染</h4>
<p>  对于超薄表面，Disney假设他散射的入射点和出射点位于同一点，和固体物体一样，仍然使用specTrans参数在完全漫反射和完全光泽(包括反射和折射)之间混合。</p>
<h2 id="渲染方程">渲染方程</h2>
<pre><code class="language-math">光从x向方向w_o发射的辐射亮度 = 光源或者自发光在x处沿w_o的辐射亮度 + x处沿w_o防线的来自反射/折射的辐射亮度
</code></pre>
<p>通常反射/折射的辐射亮度需要对点x法线方向的半空间进行积分。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《全局光照技术》笔记-第一章]]></title>
        <id>https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-yi-zhang</id>
        <link href="https://zanegjun.github.io/post/lesslessquan-ju-guang-zhao-ji-zhu-greatergreater-bi-ji-di-yi-zhang">
        </link>
        <updated>2020-02-03T12:04:10.000Z</updated>
        <summary type="html"><![CDATA[<p>介绍全局光照的基础概念</p>
]]></summary>
        <content type="html"><![CDATA[<p>介绍全局光照的基础概念</p>
<!-- more -->
<h2 id="11全局光照总览">1.1全局光照总览</h2>
<p>  主要介绍了全局光包含的几个大的方面，形成总体的认识。包括了以下几个方面。</p>
<ol>
<li>阴影。包括软阴影、硬阴影，应该是ShadowMap</li>
<li>环境遮蔽(AO)。主要增加考虑遮挡关系，使得阴影处的渲染更加逼真自然。一般离线生成，SSAO</li>
<li>反射。使用IBL采样Cubemap</li>
<li>间接光照。是全局光照最重要的部分，有各种技术，IBL，LightMap,</li>
<li>求谐光照(SH),LightProbe等等</li>
<li>焦散</li>
<li>散射</li>
</ol>
<h2 id="12辐射度量学">1.2辐射度量学</h2>
<ol>
<li>立体角。2d角度概念在3d的延伸,表示在3d空间中，从某个点观察，另一个物体有多“大”；以可以理解为3D空间中以某一点为起点的多个方向集合。通常使用单位球上一块区域面积大小来表示其对应的立体角大小。</li>
<li>辐射能量。基本单位</li>
<li>辐射亮度。从面A的一部分射出的光能量，是我们渲染方程最终要计算得值。计算的是单束光的量度。</li>
<li>辐射强度。面积A在某个方向上的辐射强度。</li>
<li>辐射照度（Irradiance）。一个点接收的来自各个方向的辐射亮度，表示表面的一个点接收的所有光照。LightMap中存储的就是辐射照度。</li>
</ol>
<h2 id="13-物体的表面着色">1.3 物体的表面着色</h2>
<ol>
<li>两种光学模型，波动光学与几何光学。波动光学由于以光的波长为测量尺寸，大大超出了计算机图形学的需求，所以计算机图形学中主要以几何光学作为光学模型。几何光学作出了几个假设:</li>
</ol>
<ul>
<li>物体表面绝对光滑</li>
<li>光仅可以被发射，反射或者传播</li>
<li>光以无限快的速度沿直线传播<br>
从以上几个假设下，反射有反射定律决定。</li>
</ul>
<ol start="2">
<li>光与表面的交互过程可以被以下描述：</li>
</ol>
<pre><code>graph LR
光源--&gt;与物体进行交互,部分被反射,部分被吸收并经过一定路径传播后沿其他方向从物体表面散射--&gt;被感应器接收形成图像
</code></pre>
<ol start="3">
<li>光源可以简单分为平行光，点光源，聚光灯</li>
<li>材质决定物体表面与光交互的一切。一般假设表面是绝对光滑的，但是实际情况是物体表面在一个像素尺度上，是不光滑的。<br>
在图形学中，材质可以分为两大类：<strong>金属与非金属</strong></li>
</ol>
<ul>
<li>金属：立即吸收所有折射的光照</li>
<li>非金属：折射光照在物体内部传播并根据物体属性在沿某个方向离开物体<br>
<strong>这种由物体内部发射回来的光通常不具有固定的方向性，所以这种反射成为漫反射(scattering)</strong><br>
在计算机图形学中，通常将反射和漫反射区分开，分别称为光泽(Specular)和漫反射(Diffuse)。</li>
<li><strong>Specular</strong>:光在物体表面的直接反射形成</li>
<li><strong>Diffuse</strong>:光进入物体表面，经过折射，吸收，多次散射过程之后重新从物体表面散射回表面外的光形成。漫反射光可以接受来自全部方向的光，因此需要对全空间进行积分计算，但是将与方向无关的部分分离，可以使用更简单的方法处理</li>
</ul>
<ol start="5">
<li>感应器如摄像机接受图像后会进行光栅化，但是会引起锯齿，这是由于采样不足导致的走样现象，相应有避免这种现象的反走样技术。</li>
</ol>
<h2 id="14-采样和反走样">1.4 采样和反走样</h2>
<p><strong>3D图像生成的本质是对各种连续函数(几何图形,BRDF分布函数)的采样,然后转化为对应的离散函数的过程。大部分采样发生在光栅化阶段。</strong></p>
<ol>
<li><strong>傅里叶变换</strong>：任何非周期的连续函数可以用正弦和/余弦和乘以一个加权函数的积分来表示，这个积分方程为傅里叶变换。傅里叶变换将一个连续非周期函数由其时间域或者空间域变换到其频率域。目的是在频率域我们可以发现该函数的一些重要特征，甚至一些对函数的操作在频率域进行更方便。</li>
<li><strong>卷积</strong>：两个函数f和g,在其中一个函数翻转180°之后，两个函数乘积的积分。<br>
<strong>卷积定理</strong>：对于卷积和傅里叶变换，可以证明，空间域中两个函数的卷积的傅里叶变换等于两个函数的傅里叶变换在频率域的乘积；反过来，如果有两个变换的乘积，可以通过计算傅里叶反变换得到空间域的卷积</li>
<li><strong>采样定理</strong>：冲激函数具有采样特性，可以简单地得到冲激位置处的函数值，那么如果我们定义一个具有均匀间隔的冲激函数，将这个冲激串作用于一个连续函数，那么其结果就得到对原始信号的均匀采样。借助冲激函数的傅里叶变换和卷积定理，可以得出采样定理，进而指导我们对函数进行采样。<strong>冲激串函数的傅里叶变换仍然是一个冲激串函数</strong>。一个连续函数被采样成一个离散函数后，其能够被重建为原函数的能力取决于采样点的密度，或称为采样率。<strong>采样率必须大于等于2x最大频率采样点/秒才能够被完美复原</strong></li>
<li><strong>几何走样</strong>:</li>
</ol>
<ul>
<li><strong>光栅化本质：</strong> 按照屏幕分辨率对可见性函数进行采样，即采样点之间的间距为一个像素，采样点的位置为每个像素的中点。</li>
<li><strong>几何走样：</strong> 由于对几何图形的可见性函数采样导致的走样称为几何走样，是计算机图形学中最严重的走样现象。<mark>这是由于可见性函数是一个连续函数，想要呈现很好的图像，必须要在图像上还原出很好的原始可见性函数，根据采样定律，必须使用两倍于可见性函数最高频率的采样率。但是三角形的可见性总是存在不连续，这种不连续导致无限大的频率，从而使其傅里叶变换不存在有限的频率带宽，因此没有采样率可以阻止走样发生；同时根据傅里叶变换的条件，只有定义域在无限的时间域或者空间域才能使其傅里叶变换具有有限的频率带宽，所以对于计算机图形学中有限的二维或者三维空间域，走样现象是不可避免的</mark>。</li>
<li><strong>着色走样：</strong> 由于像素着色器受限于屏幕分辨率所限导致的。主要是指，在着色器中对一些以分析的方式得到的连续函数的采样不足导致走样，而不是对纹理的采样不足。解决思路主要是将一些外部参数融入到光照计算，如BRDF，使“原始连续函数”更加平缓，在对这些光照结果采样。</li>
<li><strong>时间走样：</strong> 由于渲染帧率的限制使其对运动过程的采样不足导致的走样。解决方法一是运动模糊，但是计算成本高；二是针对当前帧渲染结果，生成一个速率缓存，然后使用这些方向在后处理阶段对其邻近像素点进行插值计算。</li>
</ul>
<ol start="5">
<li><strong>重建</strong> 卷积计算最本质也是最直观的特征是平滑，它通过对f的每个点考虑该点周围一定范围内的值对该点的影响，来消除该点与周围环境的频率的快速变化。这在计算机图形学运用广泛，大部分可能出现走样的地方，都可以在采样之前对原始函数进行平滑，以减轻走样现象。<mark>图像处理中，卷积的意义相当于使用一个蒙版遍历每一个像素点，分别计算蒙版内所有乘积的和，GPU中纹理过滤相关技术都是通过卷积的方式实现</mark></li>
<li><strong>重采样</strong> 最近邻内插值法、双线性插值法等。</li>
<li><strong>屏幕反走样</strong> 几何走样、着色器走样都跟屏幕分辨率有关，如果能从像素着色器解决走样问题,或许就能解决所有由于分辨率带来的走样。<mark>走样是一个采样问题，不能通过任何技术手段在采样之后消除这种由于采样不足导致的走样。走样是由于采样率低导致傅里叶变换的高频部分没有被覆盖，从而使相邻的采样点之间出现较大的差异。</mark></li>
</ol>
<ul>
<li><strong>过采样/超采样</strong> 针对特定分辨率的反走样技术，通过使用一个比输出分辨率略高的采样率对原始函数进行采样并对这个高分辨率的样本函数使用滤波器进行平滑，然后对这个高分辨率的样本函数进行重采样得到输出分辨率的图像。</li>
<li><strong>FSAA(全屏反走样)</strong> 以高分辨率渲染，然后对于相邻采样点取平均值得到最终图像。优点是实现简单，缺点是计算量大，每个子采样点都需要被进行一次着色。</li>
<li><strong>MSAA(多重采样反走样)</strong> 对于每个像素生成多个子采样点，并计算每个子采样点的深度和模板值，而对于颜色值，光栅化器对每个像素只调用一次像素着色器，然后将计算结果复制给每个子采样点。<mark>由于像素着色器只计算一次，相对FSAA大大减少了计算量，但是内存占用并没有减少。</mark> 纹理采样的位置一般是使用像素中心点位置，但是在MSAA下,几何图形可能只占据像素的小部分区域并不包括中心点,这时候再使用中心点采样纹理是不正确的；为了确保颜色采样的正确性,这个像素着色器使用的采样位置可以被调整到覆盖区域中某个点的位置，这种技术称为<strong>质心采样</strong>。<mark>对于一个被几何图形覆盖的像素点，它首先从像素中心点开始寻找，如果中心点没有被几何图形覆盖，则一次向外延伸直到找到一个被覆盖的子采样点，该点的位置将作为最终像素着色器对纹理采样的位置。</mark></li>
</ul>
]]></content>
    </entry>
</feed>